{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7242cc",
   "metadata": {},
   "source": [
    "# Practice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebc2183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>Category_Index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>书籍</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书籍</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>书籍</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书籍</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62769</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "      <td>我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62770</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9997</td>\n",
       "      <td>0</td>\n",
       "      <td>房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62771</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9998</td>\n",
       "      <td>0</td>\n",
       "      <td>我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62772</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62773</th>\n",
       "      <td>酒店</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62774 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat  Category_Index  label  \\\n",
       "0      书籍               1      1   \n",
       "1      书籍               2      1   \n",
       "2      书籍               3      1   \n",
       "3      书籍               4      1   \n",
       "4      书籍               5      1   \n",
       "...    ..             ...    ...   \n",
       "62769  酒店            9996      0   \n",
       "62770  酒店            9997      0   \n",
       "62771  酒店            9998      0   \n",
       "62772  酒店            9999      0   \n",
       "62773  酒店           10000      0   \n",
       "\n",
       "                                                  review  \n",
       "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...  \n",
       "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...  \n",
       "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...  \n",
       "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...  \n",
       "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...  \n",
       "...                                                  ...  \n",
       "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...  \n",
       "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...  \n",
       "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！  \n",
       "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...  \n",
       "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...  \n",
       "\n",
       "[62774 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 讀取CSV文件\n",
    "data = pd.read_csv('simplified_dataset/simplified_raw_data.csv')  # 替換成你的CSV文件路徑\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771e91f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/32/17fwcjcd1kv9vkdd_3w2k4vw0000gn/T/jieba.cache\n",
      "Loading model cost 0.358 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>Category_Index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>分詞描述</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...</td>\n",
       "      <td>﻿ 做 父母 一定 要 有 刘墉 这样 的 心态 ， 不断 地 学习 ， 不断 地 进步 ，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>书籍</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "      <td>作者 真有 英国人 严谨 的 风格 ， 提出 观点 、 进行 论述 论证 ， 尽管 本人 对...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书籍</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "      <td>作者 长篇大论 借用 详细 报告 数据处理 工作 和 计算结果 支持 其新 观点 。 为什么...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>书籍</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "      <td>作者 在 战 几时 之前 用 了 ＂ 拥抱 ＂ 令人 叫绝 ． 日本 如果 没有 战败 ， ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书籍</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "      <td>作者 在 少年 时即 喜 阅读 ， 能 看出 他 精读 了 无数 经典 ， 因而 他 有 一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62769</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "      <td>我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...</td>\n",
       "      <td>我们 去 盐城 的 时候 那里 的 最低气温 只有 4 度 ， 晚上 冷得 要死 ， 居然 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62770</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9997</td>\n",
       "      <td>0</td>\n",
       "      <td>房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...</td>\n",
       "      <td>房间 很小 ， 整体 设施 老化 ， 和 四星 的 差距 很大 。 毛巾 太 破旧 了 。 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62771</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9998</td>\n",
       "      <td>0</td>\n",
       "      <td>我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！</td>\n",
       "      <td>我 感觉 不行 。 。 。 性价比 很差 。 不 知道 是 银川 都 这样 还是 怎么 的 ！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62772</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...</td>\n",
       "      <td>房间 时间 长 ， 进去 有点 异味 ！ 服务员 是不是 不够 用 啊 ！ 我 在 一楼 找...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62773</th>\n",
       "      <td>酒店</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...</td>\n",
       "      <td>老人 小孩 一 大家族 聚会 ， 选在 吴宫 泛太平洋 ， 以为 新加坡 品牌 一定 很 不...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62774 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat  Category_Index  label  \\\n",
       "0      书籍               1      1   \n",
       "1      书籍               2      1   \n",
       "2      书籍               3      1   \n",
       "3      书籍               4      1   \n",
       "4      书籍               5      1   \n",
       "...    ..             ...    ...   \n",
       "62769  酒店            9996      0   \n",
       "62770  酒店            9997      0   \n",
       "62771  酒店            9998      0   \n",
       "62772  酒店            9999      0   \n",
       "62773  酒店           10000      0   \n",
       "\n",
       "                                                  review  \\\n",
       "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...   \n",
       "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...   \n",
       "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...   \n",
       "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...   \n",
       "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...   \n",
       "...                                                  ...   \n",
       "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...   \n",
       "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...   \n",
       "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！   \n",
       "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...   \n",
       "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...   \n",
       "\n",
       "                                                    分詞描述  \n",
       "0      ﻿ 做 父母 一定 要 有 刘墉 这样 的 心态 ， 不断 地 学习 ， 不断 地 进步 ，...  \n",
       "1      作者 真有 英国人 严谨 的 风格 ， 提出 观点 、 进行 论述 论证 ， 尽管 本人 对...  \n",
       "2      作者 长篇大论 借用 详细 报告 数据处理 工作 和 计算结果 支持 其新 观点 。 为什么...  \n",
       "3      作者 在 战 几时 之前 用 了 ＂ 拥抱 ＂ 令人 叫绝 ． 日本 如果 没有 战败 ， ...  \n",
       "4      作者 在 少年 时即 喜 阅读 ， 能 看出 他 精读 了 无数 经典 ， 因而 他 有 一...  \n",
       "...                                                  ...  \n",
       "62769  我们 去 盐城 的 时候 那里 的 最低气温 只有 4 度 ， 晚上 冷得 要死 ， 居然 ...  \n",
       "62770  房间 很小 ， 整体 设施 老化 ， 和 四星 的 差距 很大 。 毛巾 太 破旧 了 。 ...  \n",
       "62771    我 感觉 不行 。 。 。 性价比 很差 。 不 知道 是 银川 都 这样 还是 怎么 的 ！  \n",
       "62772  房间 时间 长 ， 进去 有点 异味 ！ 服务员 是不是 不够 用 啊 ！ 我 在 一楼 找...  \n",
       "62773  老人 小孩 一 大家族 聚会 ， 选在 吴宫 泛太平洋 ， 以为 新加坡 品牌 一定 很 不...  \n",
       "\n",
       "[62774 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分詞函數\n",
    "def segment_text(text):\n",
    "    # 檢查是否是字串，如果不是，則返回一個空字串\n",
    "    if isinstance(text, str):\n",
    "        return \" \".join(jieba.cut(text))\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# 對文字描述進行分詞\n",
    "data['分詞描述'] = data['review'].apply(segment_text)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f615cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 48437)\t1\n",
      "  (0, 50210)\t1\n",
      "  (0, 5951)\t1\n",
      "  (0, 14774)\t1\n",
      "  (0, 33575)\t1\n",
      "  (0, 26891)\t1\n",
      "  (0, 4061)\t1\n",
      "  (0, 55496)\t1\n",
      "  (0, 38364)\t1\n",
      "  (0, 50264)\t1\n"
     ]
    }
   ],
   "source": [
    "# 劃分數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['分詞描述'], data['cat'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 特徵提取 - 使用詞袋模型\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_vectorized[0])  # (i,j) f. -> 第i筆資料出現第j個詞的頻率次數f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d12ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率：0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.93      0.93      0.93       759\n",
      "          平板       0.77      0.79      0.78      1998\n",
      "          手机       0.95      0.73      0.83       482\n",
      "          水果       0.89      0.88      0.88      1936\n",
      "         洗发水       0.80      0.85      0.82      2008\n",
      "         热水器       1.00      0.05      0.10       117\n",
      "          蒙牛       0.99      0.92      0.96       409\n",
      "          衣服       0.86      0.88      0.87      1999\n",
      "         计算机       0.93      0.87      0.90       813\n",
      "          酒店       0.95      0.99      0.97      2034\n",
      "\n",
      "    accuracy                           0.87     12555\n",
      "   macro avg       0.91      0.79      0.80     12555\n",
      "weighted avg       0.87      0.87      0.87     12555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 訓練貝氏分類器\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# 預測並評估模型\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"準確率：{accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f041a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ceaafa4",
   "metadata": {},
   "source": [
    "# Practice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37858ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cat  Category_Index  label  \\\n",
      "0      书籍               1      1   \n",
      "1      书籍               2      1   \n",
      "2      书籍               3      1   \n",
      "3      书籍               4      1   \n",
      "4      书籍               5      1   \n",
      "...    ..             ...    ...   \n",
      "62769  酒店            9996      0   \n",
      "62770  酒店            9997      0   \n",
      "62771  酒店            9998      0   \n",
      "62772  酒店            9999      0   \n",
      "62773  酒店           10000      0   \n",
      "\n",
      "                                                  review  \\\n",
      "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...   \n",
      "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...   \n",
      "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...   \n",
      "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...   \n",
      "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...   \n",
      "...                                                  ...   \n",
      "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...   \n",
      "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...   \n",
      "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！   \n",
      "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...   \n",
      "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...   \n",
      "\n",
      "                                                    字符描述  \n",
      "0      ﻿ 做 父 母 一 定 要 有 刘 墉 这 样 的 心 态 ， 不 断 地 学 习 ， 不 ...  \n",
      "1      作 者 真 有 英 国 人 严 谨 的 风 格 ， 提 出 观 点 、 进 行 论 述 论 ...  \n",
      "2      作 者 长 篇 大 论 借 用 详 细 报 告 数 据 处 理 工 作 和 计 算 结 果 ...  \n",
      "3      作 者 在 战 几 时 之 前 用 了 ＂ 拥 抱 ＂ 令 人 叫 绝 ． 日 本 如 果 ...  \n",
      "4      作 者 在 少 年 时 即 喜 阅 读 ， 能 看 出 他 精 读 了 无 数 经 典 ， ...  \n",
      "...                                                  ...  \n",
      "62769  我 们 去 盐 城 的 时 候 那 里 的 最 低 气 温 只 有 4 度 ， 晚 上 冷 ...  \n",
      "62770  房 间 很 小 ， 整 体 设 施 老 化 ， 和 四 星 的 差 距 很 大 。 毛 巾 ...  \n",
      "62771  我 感 觉 不 行 。 。 。 性 价 比 很 差 。 不 知 道 是 银 川 都 这 样 ...  \n",
      "62772  房 间 时 间 长 ， 进 去 有 点 异 味 ！ 服 务 员 是 不 是 不 够 用 啊 ...  \n",
      "62773  老 人 小 孩 一 大 家 族 聚 会 ， 选 在 吴 宫 泛 太 平 洋 ， 以 为 新 ...  \n",
      "\n",
      "[62774 rows x 5 columns]\n",
      "準確率：0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.92      0.92      0.92       759\n",
      "          平板       0.76      0.70      0.73      1998\n",
      "          手机       0.78      0.77      0.78       482\n",
      "          水果       0.90      0.87      0.88      1936\n",
      "         洗发水       0.78      0.85      0.81      2008\n",
      "         热水器       0.93      0.35      0.51       117\n",
      "          蒙牛       0.94      0.99      0.97       409\n",
      "          衣服       0.84      0.88      0.86      1999\n",
      "         计算机       0.81      0.84      0.82       813\n",
      "          酒店       0.97      0.96      0.97      2034\n",
      "\n",
      "    accuracy                           0.85     12555\n",
      "   macro avg       0.86      0.81      0.82     12555\n",
      "weighted avg       0.85      0.85      0.85     12555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 讀取CSV文件\n",
    "data = pd.read_csv('simplified_dataset/simplified_raw_data.csv')  # 替換成你的CSV文件路徑\n",
    "\n",
    "# 將每個字都當作特徵，不進行分詞\n",
    "data['字符描述'] = data['review'].apply(lambda text: \" \".join(list(str(text))) if isinstance(text, str) else \"\")\n",
    "print(data)\n",
    "\n",
    "# 劃分數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['字符描述'], data['cat'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 特徵提取 - 使用詞袋模型 (字符级别)\n",
    "vectorizer = CountVectorizer(analyzer='char')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# 訓練貝氏分類器\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# 預測並評估模型\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"準確率：{accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fddd5",
   "metadata": {},
   "source": [
    "# Practice3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecabb774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "Feature names: ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# 轉換文本數據為特徵矩陣\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# 獲取特徵名稱\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 打印特徵矩陣\n",
    "print(X.toarray())\n",
    "print(\"Feature names:\", feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf16ff",
   "metadata": {},
   "source": [
    "# single word\n",
    "\n",
    "classifier : MultinomialNB , DecisionTree , RandomForest , SVM , MLP\n",
    "\n",
    "dataset : train - 80 percentage  , test - 20 percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef5c3592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MultinomialNB, Feature Extraction: Character Level\n",
      "      cat  Category_Index  label  \\\n",
      "0      书籍               1      1   \n",
      "1      书籍               2      1   \n",
      "2      书籍               3      1   \n",
      "3      书籍               4      1   \n",
      "4      书籍               5      1   \n",
      "...    ..             ...    ...   \n",
      "62769  酒店            9996      0   \n",
      "62770  酒店            9997      0   \n",
      "62771  酒店            9998      0   \n",
      "62772  酒店            9999      0   \n",
      "62773  酒店           10000      0   \n",
      "\n",
      "                                                  review  \\\n",
      "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...   \n",
      "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...   \n",
      "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...   \n",
      "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...   \n",
      "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...   \n",
      "...                                                  ...   \n",
      "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...   \n",
      "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...   \n",
      "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！   \n",
      "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...   \n",
      "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...   \n",
      "\n",
      "                                                    字符描述  \n",
      "0      ﻿ 做 父 母 一 定 要 有 刘 墉 这 样 的 心 态 ， 不 断 地 学 习 ， 不 ...  \n",
      "1      作 者 真 有 英 国 人 严 谨 的 风 格 ， 提 出 观 点 、 进 行 论 述 论 ...  \n",
      "2      作 者 长 篇 大 论 借 用 详 细 报 告 数 据 处 理 工 作 和 计 算 结 果 ...  \n",
      "3      作 者 在 战 几 时 之 前 用 了 ＂ 拥 抱 ＂ 令 人 叫 绝 ． 日 本 如 果 ...  \n",
      "4      作 者 在 少 年 时 即 喜 阅 读 ， 能 看 出 他 精 读 了 无 数 经 典 ， ...  \n",
      "...                                                  ...  \n",
      "62769  我 们 去 盐 城 的 时 候 那 里 的 最 低 气 温 只 有 4 度 ， 晚 上 冷 ...  \n",
      "62770  房 间 很 小 ， 整 体 设 施 老 化 ， 和 四 星 的 差 距 很 大 。 毛 巾 ...  \n",
      "62771  我 感 觉 不 行 。 。 。 性 价 比 很 差 。 不 知 道 是 银 川 都 这 样 ...  \n",
      "62772  房 间 时 间 长 ， 进 去 有 点 异 味 ！ 服 务 员 是 不 是 不 够 用 啊 ...  \n",
      "62773  老 人 小 孩 一 大 家 族 聚 会 ， 选 在 吴 宫 泛 太 平 洋 ， 以 为 新 ...  \n",
      "\n",
      "[62774 rows x 5 columns]\n",
      "Accuracy: 0.85\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.92      0.92      0.92       759\n",
      "          平板       0.76      0.70      0.73      1998\n",
      "          手机       0.78      0.77      0.78       482\n",
      "          水果       0.90      0.87      0.88      1936\n",
      "         洗发水       0.78      0.85      0.81      2008\n",
      "         热水器       0.93      0.35      0.51       117\n",
      "          蒙牛       0.94      0.99      0.97       409\n",
      "          衣服       0.84      0.88      0.86      1999\n",
      "         计算机       0.81      0.84      0.82       813\n",
      "          酒店       0.97      0.96      0.97      2034\n",
      "\n",
      "    accuracy                           0.85     12555\n",
      "   macro avg       0.86      0.81      0.82     12555\n",
      "weighted avg       0.85      0.85      0.85     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 699   26    9    2   12    0    2    1    6    2]\n",
      " [  15 1400   50   53  231    0    7  155   78    9]\n",
      " [   6   63  371    5    2    0    0    8   23    4]\n",
      " [  13   52    3 1685  109    1    4   53   11    5]\n",
      " [   8  121    5   67 1698    2    7   70   18   12]\n",
      " [   0   13    0   12   20   41    1   19    8    3]\n",
      " [   2    0    0    0    0    0  406    0    0    1]\n",
      " [   8   88    3   41   90    0    4 1751    4   10]\n",
      " [   5   74   28    5   12    0    0    3  679    7]\n",
      " [   7   15    4    7    7    0    1   19   12 1962]]\n",
      "\n",
      "Classifier: DecisionTree, Feature Extraction: Character Level\n",
      "      cat  Category_Index  label  \\\n",
      "0      书籍               1      1   \n",
      "1      书籍               2      1   \n",
      "2      书籍               3      1   \n",
      "3      书籍               4      1   \n",
      "4      书籍               5      1   \n",
      "...    ..             ...    ...   \n",
      "62769  酒店            9996      0   \n",
      "62770  酒店            9997      0   \n",
      "62771  酒店            9998      0   \n",
      "62772  酒店            9999      0   \n",
      "62773  酒店           10000      0   \n",
      "\n",
      "                                                  review  \\\n",
      "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...   \n",
      "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...   \n",
      "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...   \n",
      "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...   \n",
      "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...   \n",
      "...                                                  ...   \n",
      "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...   \n",
      "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...   \n",
      "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！   \n",
      "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...   \n",
      "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...   \n",
      "\n",
      "                                                    字符描述  \n",
      "0      ﻿ 做 父 母 一 定 要 有 刘 墉 这 样 的 心 态 ， 不 断 地 学 习 ， 不 ...  \n",
      "1      作 者 真 有 英 国 人 严 谨 的 风 格 ， 提 出 观 点 、 进 行 论 述 论 ...  \n",
      "2      作 者 长 篇 大 论 借 用 详 细 报 告 数 据 处 理 工 作 和 计 算 结 果 ...  \n",
      "3      作 者 在 战 几 时 之 前 用 了 ＂ 拥 抱 ＂ 令 人 叫 绝 ． 日 本 如 果 ...  \n",
      "4      作 者 在 少 年 时 即 喜 阅 读 ， 能 看 出 他 精 读 了 无 数 经 典 ， ...  \n",
      "...                                                  ...  \n",
      "62769  我 们 去 盐 城 的 时 候 那 里 的 最 低 气 温 只 有 4 度 ， 晚 上 冷 ...  \n",
      "62770  房 间 很 小 ， 整 体 设 施 老 化 ， 和 四 星 的 差 距 很 大 。 毛 巾 ...  \n",
      "62771  我 感 觉 不 行 。 。 。 性 价 比 很 差 。 不 知 道 是 银 川 都 这 样 ...  \n",
      "62772  房 间 时 间 长 ， 进 去 有 点 异 味 ！ 服 务 员 是 不 是 不 够 用 啊 ...  \n",
      "62773  老 人 小 孩 一 大 家 族 聚 会 ， 选 在 吴 宫 泛 太 平 洋 ， 以 为 新 ...  \n",
      "\n",
      "[62774 rows x 5 columns]\n",
      "Accuracy: 0.79\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.84      0.82      0.83       759\n",
      "          平板       0.65      0.64      0.65      1998\n",
      "          手机       0.64      0.58      0.61       482\n",
      "          水果       0.84      0.85      0.85      1936\n",
      "         洗发水       0.73      0.74      0.73      2008\n",
      "         热水器       0.48      0.37      0.42       117\n",
      "          蒙牛       1.00      0.99      1.00       409\n",
      "          衣服       0.80      0.84      0.82      1999\n",
      "         计算机       0.73      0.73      0.73       813\n",
      "          酒店       0.93      0.92      0.93      2034\n",
      "\n",
      "    accuracy                           0.79     12555\n",
      "   macro avg       0.76      0.75      0.75     12555\n",
      "weighted avg       0.79      0.79      0.79     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 623   27   11   24   27    2    0   15   15   15]\n",
      " [  31 1287   85   73  219   13    0  145  101   44]\n",
      " [  14  108  279    7   11    4    0   18   35    6]\n",
      " [  24   78    4 1645  103    4    0   57    8   13]\n",
      " [  13  215    5  112 1480   11    0  119   30   23]\n",
      " [   1   32    4    2   20   43    0    7    4    4]\n",
      " [   0    0    0    2    0    0  406    0    0    1]\n",
      " [   6  101   12   51  113    6    0 1675    5   30]\n",
      " [  16   91   32   17   41    2    0   14  593    7]\n",
      " [  18   30    7   18   19    5    1   42   17 1877]]\n",
      "\n",
      "Classifier: RandomForest, Feature Extraction: Character Level\n",
      "      cat  Category_Index  label  \\\n",
      "0      书籍               1      1   \n",
      "1      书籍               2      1   \n",
      "2      书籍               3      1   \n",
      "3      书籍               4      1   \n",
      "4      书籍               5      1   \n",
      "...    ..             ...    ...   \n",
      "62769  酒店            9996      0   \n",
      "62770  酒店            9997      0   \n",
      "62771  酒店            9998      0   \n",
      "62772  酒店            9999      0   \n",
      "62773  酒店           10000      0   \n",
      "\n",
      "                                                  review  \\\n",
      "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...   \n",
      "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...   \n",
      "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...   \n",
      "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...   \n",
      "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...   \n",
      "...                                                  ...   \n",
      "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...   \n",
      "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...   \n",
      "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！   \n",
      "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...   \n",
      "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...   \n",
      "\n",
      "                                                    字符描述  \n",
      "0      ﻿ 做 父 母 一 定 要 有 刘 墉 这 样 的 心 态 ， 不 断 地 学 习 ， 不 ...  \n",
      "1      作 者 真 有 英 国 人 严 谨 的 风 格 ， 提 出 观 点 、 进 行 论 述 论 ...  \n",
      "2      作 者 长 篇 大 论 借 用 详 细 报 告 数 据 处 理 工 作 和 计 算 结 果 ...  \n",
      "3      作 者 在 战 几 时 之 前 用 了 ＂ 拥 抱 ＂ 令 人 叫 绝 ． 日 本 如 果 ...  \n",
      "4      作 者 在 少 年 时 即 喜 阅 读 ， 能 看 出 他 精 读 了 无 数 经 典 ， ...  \n",
      "...                                                  ...  \n",
      "62769  我 们 去 盐 城 的 时 候 那 里 的 最 低 气 温 只 有 4 度 ， 晚 上 冷 ...  \n",
      "62770  房 间 很 小 ， 整 体 设 施 老 化 ， 和 四 星 的 差 距 很 大 。 毛 巾 ...  \n",
      "62771  我 感 觉 不 行 。 。 。 性 价 比 很 差 。 不 知 道 是 银 川 都 这 样 ...  \n",
      "62772  房 间 时 间 长 ， 进 去 有 点 异 味 ！ 服 务 员 是 不 是 不 够 用 啊 ...  \n",
      "62773  老 人 小 孩 一 大 家 族 聚 会 ， 选 在 吴 宫 泛 太 平 洋 ， 以 为 新 ...  \n",
      "\n",
      "[62774 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.97      0.89      0.93       759\n",
      "          平板       0.72      0.80      0.76      1998\n",
      "          手机       0.95      0.60      0.73       482\n",
      "          水果       0.90      0.89      0.89      1936\n",
      "         洗发水       0.78      0.84      0.81      2008\n",
      "         热水器       0.95      0.30      0.45       117\n",
      "          蒙牛       1.00      1.00      1.00       409\n",
      "          衣服       0.85      0.90      0.87      1999\n",
      "         计算机       0.94      0.77      0.84       813\n",
      "          酒店       0.97      0.96      0.97      2034\n",
      "\n",
      "    accuracy                           0.86     12555\n",
      "   macro avg       0.90      0.79      0.83     12555\n",
      "weighted avg       0.87      0.86      0.86     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 676   21    0   11   29    0    0   11    3    8]\n",
      " [   5 1607   12   43  198    1    0  108   13   11]\n",
      " [   4  139  287    6    4    0    0   13   25    4]\n",
      " [   3   48    0 1719  121    0    0   42    1    2]\n",
      " [   1  138    0   75 1696    0    1   89    0    8]\n",
      " [   1   40    0    1   26   35    0   11    0    3]\n",
      " [   0    0    0    1    0    0  408    0    0    0]\n",
      " [   3   91    0   31   72    1    0 1792    0    9]\n",
      " [   3  113    3   17   33    0    0   11  625    8]\n",
      " [   3   31    0    7    9    0    1   23    1 1959]]\n",
      "\n",
      "Classifier: SVM, Feature Extraction: Character Level\n",
      "      cat  Category_Index  label  \\\n",
      "0      书籍               1      1   \n",
      "1      书籍               2      1   \n",
      "2      书籍               3      1   \n",
      "3      书籍               4      1   \n",
      "4      书籍               5      1   \n",
      "...    ..             ...    ...   \n",
      "62769  酒店            9996      0   \n",
      "62770  酒店            9997      0   \n",
      "62771  酒店            9998      0   \n",
      "62772  酒店            9999      0   \n",
      "62773  酒店           10000      0   \n",
      "\n",
      "                                                  review  \\\n",
      "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...   \n",
      "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...   \n",
      "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...   \n",
      "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...   \n",
      "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...   \n",
      "...                                                  ...   \n",
      "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...   \n",
      "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...   \n",
      "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！   \n",
      "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...   \n",
      "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...   \n",
      "\n",
      "                                                    字符描述  \n",
      "0      ﻿ 做 父 母 一 定 要 有 刘 墉 这 样 的 心 态 ， 不 断 地 学 习 ， 不 ...  \n",
      "1      作 者 真 有 英 国 人 严 谨 的 风 格 ， 提 出 观 点 、 进 行 论 述 论 ...  \n",
      "2      作 者 长 篇 大 论 借 用 详 细 报 告 数 据 处 理 工 作 和 计 算 结 果 ...  \n",
      "3      作 者 在 战 几 时 之 前 用 了 ＂ 拥 抱 ＂ 令 人 叫 绝 ． 日 本 如 果 ...  \n",
      "4      作 者 在 少 年 时 即 喜 阅 读 ， 能 看 出 他 精 读 了 无 数 经 典 ， ...  \n",
      "...                                                  ...  \n",
      "62769  我 们 去 盐 城 的 时 候 那 里 的 最 低 气 温 只 有 4 度 ， 晚 上 冷 ...  \n",
      "62770  房 间 很 小 ， 整 体 设 施 老 化 ， 和 四 星 的 差 距 很 大 。 毛 巾 ...  \n",
      "62771  我 感 觉 不 行 。 。 。 性 价 比 很 差 。 不 知 道 是 银 川 都 这 样 ...  \n",
      "62772  房 间 时 间 长 ， 进 去 有 点 异 味 ！ 服 务 员 是 不 是 不 够 用 啊 ...  \n",
      "62773  老 人 小 孩 一 大 家 族 聚 会 ， 选 在 吴 宫 泛 太 平 洋 ， 以 为 新 ...  \n",
      "\n",
      "[62774 rows x 5 columns]\n",
      "Accuracy: 0.70\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.93      0.61      0.73       759\n",
      "          平板       0.54      0.57      0.56      1998\n",
      "          手机       0.88      0.27      0.41       482\n",
      "          水果       0.86      0.75      0.80      1936\n",
      "         洗发水       0.64      0.72      0.68      2008\n",
      "         热水器       0.00      0.00      0.00       117\n",
      "          蒙牛       0.99      0.42      0.59       409\n",
      "          衣服       0.55      0.88      0.68      1999\n",
      "         计算机       0.71      0.66      0.68       813\n",
      "          酒店       0.96      0.80      0.87      2034\n",
      "\n",
      "    accuracy                           0.70     12555\n",
      "   macro avg       0.71      0.57      0.60     12555\n",
      "weighted avg       0.73      0.70      0.69     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 460   93    0   21   80    0    0   41   42   22]\n",
      " [   2 1146    5   48  253    0    0  499   36    9]\n",
      " [   4  158  128    5    7    0    0   76   91   13]\n",
      " [   7  106    0 1453  207    0    0  150    8    5]\n",
      " [   6  210    1   44 1448    0    0  283   10    6]\n",
      " [   1   24    0    4   36    0    0   47    2    3]\n",
      " [   5   53    0   19   26    0  172  115   17    2]\n",
      " [   1   75    0   37  121    0    1 1753    8    3]\n",
      " [   6  159   11   28   64    0    0    5  534    6]\n",
      " [   2  107    1   29   32    0    0  225    4 1634]]\n",
      "\n",
      "Classifier: MLP, Feature Extraction: Character Level\n",
      "      cat  Category_Index  label  \\\n",
      "0      书籍               1      1   \n",
      "1      书籍               2      1   \n",
      "2      书籍               3      1   \n",
      "3      书籍               4      1   \n",
      "4      书籍               5      1   \n",
      "...    ..             ...    ...   \n",
      "62769  酒店            9996      0   \n",
      "62770  酒店            9997      0   \n",
      "62771  酒店            9998      0   \n",
      "62772  酒店            9999      0   \n",
      "62773  酒店           10000      0   \n",
      "\n",
      "                                                  review  \\\n",
      "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...   \n",
      "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...   \n",
      "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...   \n",
      "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...   \n",
      "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...   \n",
      "...                                                  ...   \n",
      "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...   \n",
      "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...   \n",
      "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！   \n",
      "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...   \n",
      "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...   \n",
      "\n",
      "                                                    字符描述  \n",
      "0      ﻿ 做 父 母 一 定 要 有 刘 墉 这 样 的 心 态 ， 不 断 地 学 习 ， 不 ...  \n",
      "1      作 者 真 有 英 国 人 严 谨 的 风 格 ， 提 出 观 点 、 进 行 论 述 论 ...  \n",
      "2      作 者 长 篇 大 论 借 用 详 细 报 告 数 据 处 理 工 作 和 计 算 结 果 ...  \n",
      "3      作 者 在 战 几 时 之 前 用 了 ＂ 拥 抱 ＂ 令 人 叫 绝 ． 日 本 如 果 ...  \n",
      "4      作 者 在 少 年 时 即 喜 阅 读 ， 能 看 出 他 精 读 了 无 数 经 典 ， ...  \n",
      "...                                                  ...  \n",
      "62769  我 们 去 盐 城 的 时 候 那 里 的 最 低 气 温 只 有 4 度 ， 晚 上 冷 ...  \n",
      "62770  房 间 很 小 ， 整 体 设 施 老 化 ， 和 四 星 的 差 距 很 大 。 毛 巾 ...  \n",
      "62771  我 感 觉 不 行 。 。 。 性 价 比 很 差 。 不 知 道 是 银 川 都 这 样 ...  \n",
      "62772  房 间 时 间 长 ， 进 去 有 点 异 味 ！ 服 务 员 是 不 是 不 够 用 啊 ...  \n",
      "62773  老 人 小 孩 一 大 家 族 聚 会 ， 选 在 吴 宫 泛 太 平 洋 ， 以 为 新 ...  \n",
      "\n",
      "[62774 rows x 5 columns]\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.95      0.94      0.94       759\n",
      "          平板       0.79      0.79      0.79      1998\n",
      "          手机       0.81      0.83      0.82       482\n",
      "          水果       0.92      0.88      0.90      1936\n",
      "         洗发水       0.79      0.84      0.82      2008\n",
      "         热水器       0.62      0.64      0.63       117\n",
      "          蒙牛       1.00      0.98      0.99       409\n",
      "          衣服       0.87      0.88      0.88      1999\n",
      "         计算机       0.89      0.85      0.87       813\n",
      "          酒店       0.98      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.87     12555\n",
      "   macro avg       0.86      0.86      0.86     12555\n",
      "weighted avg       0.87      0.87      0.87     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 710   11    5    5   10    0    0    8    5    5]\n",
      " [  10 1571   38   28  192   17    0  102   37    3]\n",
      " [   4   49  398    1    3    2    0    8   12    5]\n",
      " [   4   54    2 1694  122    3    1   46    6    4]\n",
      " [   7  147    3   57 1693   10    0   71   10   10]\n",
      " [   0   22    2    0    9   75    0    5    2    2]\n",
      " [   2    0    0    2    1    0  402    1    0    1]\n",
      " [   1   73    7   38   93    8    1 1766    2   10]\n",
      " [   8   56   33    5   14    2    0    2  690    3]\n",
      " [   5   16    4   12    6    4    0   15    8 1964]]\n",
      "\n",
      "RESULTS\n",
      "Classifier: MultinomialNB, Feature Extraction:Character Level,: 0.85\n",
      "Classifier: DecisionTree, Feature Extraction:Character Level,: 0.79\n",
      "Classifier: RandomForest, Feature Extraction:Character Level,: 0.86\n",
      "Classifier: SVM, Feature Extraction:Character Level,: 0.70\n",
      "Classifier: MLP, Feature Extraction:Character Level,: 0.87\n",
      "\n",
      "Classification Finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# 讀取CSV文件\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "# 初始化不同的分類器\n",
    "def initialize_classifiers():\n",
    "    classifiers = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(),\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"MLP\": MLPClassifier()\n",
    "    }\n",
    "    return classifiers\n",
    "\n",
    "# 訓練、評估\n",
    "def train_and_evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)  #計算混淆矩陣\n",
    "    return {'accuracy': accuracy, 'classification_report': classification_rep, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'simplified_dataset/simplified_raw_data.csv'\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # 將NaN值替換為空字串\n",
    "    data['review'] = data['review'].fillna('')\n",
    "    \n",
    "    X = data['review']\n",
    "    y = data['cat']\n",
    "    \n",
    "    classifiers = initialize_classifiers()\n",
    "    \n",
    "    results_dict = {}  #用於儲存结果\n",
    "    \n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction: Character Level\")\n",
    "        \n",
    "        \n",
    "        # 將每個字都當作特徵，不進行分詞\n",
    "        data['字符描述'] = data['review'].apply(lambda text: \" \".join(list(str(text))) if isinstance(text, str) else \"\")\n",
    "        #print(data)\n",
    "\n",
    "        # 劃分數據集為訓練集和測試集\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data['字符描述'], data['cat'], test_size=0.2, random_state=42)\n",
    "\n",
    "        # 特徵提取 - 使用詞袋模型 (字符级别)\n",
    "        vectorizer = CountVectorizer(analyzer='char')\n",
    "        \n",
    "        X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "        X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "        \n",
    "        results = train_and_evaluate_classifier(classifier, X_train_vectorized, X_test_vectorized, y_train, y_test)\n",
    "        # 儲存结果到字典\n",
    "        results_dict[(clf_name)] = results\n",
    "\n",
    "        print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "        print(f\"Classification Report:\\n{results['classification_report']}\\n\")\n",
    "        print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\\n\")\n",
    "        \n",
    "    \n",
    "    # 統整結果\n",
    "    print(\"RESULTS\")\n",
    "    for(clf_name), results in results_dict.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction:Character Level,: {results['accuracy']:.2f}\")\n",
    "\n",
    "        \n",
    "    print(\"\\nClassification Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241f14b",
   "metadata": {},
   "source": [
    "# Word Frequency （Term Frequency，TF）\n",
    "\n",
    "用於將文本數據轉換為詞頻特徵的工具。它會計算每個文檔中每個詞彙出現的次數，並將其轉化為一個矩陣，其中每一行表示一個文檔，每一列表示一個詞彙，矩陣元素表示相應詞彙在文檔中的出現次數\n",
    "\n",
    "classifier : MultinomialNB , DecisionTree , RandomForest , SVM , MLP\n",
    "\n",
    "dataset : train - 80 percentage  , test - 20 percentage\n",
    "\n",
    "condition ：需要先用jieba切詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473e7e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MultinomialNB, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.93      0.93      0.93       759\n",
      "          平板       0.77      0.79      0.78      1998\n",
      "          手机       0.95      0.73      0.83       482\n",
      "          水果       0.89      0.88      0.88      1936\n",
      "         洗发水       0.80      0.85      0.82      2008\n",
      "         热水器       1.00      0.05      0.10       117\n",
      "          蒙牛       0.99      0.92      0.96       409\n",
      "          衣服       0.86      0.88      0.87      1999\n",
      "         计算机       0.93      0.87      0.90       813\n",
      "          酒店       0.95      0.99      0.97      2034\n",
      "\n",
      "    accuracy                           0.87     12555\n",
      "   macro avg       0.91      0.79      0.80     12555\n",
      "weighted avg       0.87      0.87      0.87     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 703   23    1   10   11    0    0    2    0    9]\n",
      " [  13 1576   12   42  172    0    0  139   24   20]\n",
      " [   0   86  353    4    3    0    0    8   21    7]\n",
      " [  13   54    0 1702  120    0    1   37    0    9]\n",
      " [   7  121    0   89 1711    0    1   64    1   14]\n",
      " [   1   35    0    8   27    6    0   24    7    9]\n",
      " [  13    2    0    4    9    0  378    0    0    3]\n",
      " [   4   83    1   45   84    0    1 1758    2   21]\n",
      " [   1   72    5    1   11    0    0    3  710   10]\n",
      " [   1    6    0   10    3    0    0    6    0 2008]]\n",
      "\n",
      "Classifier: DecisionTree, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.81      0.77      0.79       759\n",
      "          平板       0.58      0.67      0.62      1998\n",
      "          手机       0.66      0.62      0.64       482\n",
      "          水果       0.78      0.77      0.78      1936\n",
      "         洗发水       0.69      0.68      0.69      2008\n",
      "         热水器       0.46      0.38      0.42       117\n",
      "          蒙牛       1.00      0.99      1.00       409\n",
      "          衣服       0.77      0.77      0.77      1999\n",
      "         计算机       0.79      0.65      0.71       813\n",
      "          酒店       0.93      0.92      0.92      2034\n",
      "\n",
      "    accuracy                           0.75     12555\n",
      "   macro avg       0.75      0.72      0.73     12555\n",
      "weighted avg       0.76      0.75      0.76     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 581   48    9   25   32    1    0   39    8   16]\n",
      " [  19 1347   71  102  212   17    0  145   62   23]\n",
      " [   8   88  299    7   15    0    0   25   34    6]\n",
      " [  21  127    4 1498  171    7    0   82    3   23]\n",
      " [  31  278   16  163 1371   11    0  103   13   22]\n",
      " [   3   31    1    4   14   44    0   14    1    5]\n",
      " [   0    1    0    2    0    0  405    0    0    1]\n",
      " [  21  211    5   63  111   12    0 1545   11   20]\n",
      " [  14  113   43   27   41    3    0   29  527   16]\n",
      " [  15   72    8   26   15    0    0   29    7 1862]]\n",
      "\n",
      "Classifier: RandomForest, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.83\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.98      0.84      0.90       759\n",
      "          平板       0.64      0.79      0.71      1998\n",
      "          手机       0.89      0.62      0.73       482\n",
      "          水果       0.89      0.82      0.85      1936\n",
      "         洗发水       0.78      0.79      0.79      2008\n",
      "         热水器       0.58      0.38      0.46       117\n",
      "          蒙牛       1.00      1.00      1.00       409\n",
      "          衣服       0.80      0.87      0.83      1999\n",
      "         计算机       0.97      0.73      0.83       813\n",
      "          酒店       0.95      0.96      0.96      2034\n",
      "\n",
      "    accuracy                           0.83     12555\n",
      "   macro avg       0.85      0.78      0.81     12555\n",
      "weighted avg       0.84      0.83      0.83     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 635   45    0   16   21    1    0   34    0    7]\n",
      " [   2 1583   20   48  169    7    0  143    9   17]\n",
      " [   2  137  300    3    3    0    0   26    9    2]\n",
      " [   7  123    1 1586  129    3    0   68    0   19]\n",
      " [   2  222    2   67 1593    8    0   97    0   17]\n",
      " [   0   40    0    2   14   44    0   14    0    3]\n",
      " [   0    0    0    1    0    0  407    0    0    1]\n",
      " [   1  139    2   23   71   12    1 1735    0   15]\n",
      " [   2  126   11   19   27    0    0   22  592   14]\n",
      " [   0   43    1    9   10    1    0   18    1 1951]]\n",
      "\n",
      "Classifier: SVM, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.83\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.92      0.84      0.88       759\n",
      "          平板       0.66      0.80      0.72      1998\n",
      "          手机       0.94      0.56      0.70       482\n",
      "          水果       0.94      0.80      0.86      1936\n",
      "         洗发水       0.77      0.82      0.79      2008\n",
      "         热水器       1.00      0.29      0.45       117\n",
      "          蒙牛       1.00      0.98      0.99       409\n",
      "          衣服       0.84      0.87      0.85      1999\n",
      "         计算机       0.95      0.85      0.90       813\n",
      "          酒店       0.90      0.94      0.92      2034\n",
      "\n",
      "    accuracy                           0.83     12555\n",
      "   macro avg       0.89      0.78      0.81     12555\n",
      "weighted avg       0.85      0.83      0.83     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 640   53    0    6   19    0    0   14    0   27]\n",
      " [   7 1595   10   24  192    0    0  103   17   50]\n",
      " [   8  117  271    1    2    0    0   13   14   56]\n",
      " [  12  126    0 1549  161    0    0   71    0   17]\n",
      " [  10  191    0   38 1648    0    0   88    0   33]\n",
      " [   1   45    0    2   17   34    0   14    1    3]\n",
      " [   2    1    0    0    0    0  401    0    0    5]\n",
      " [   9  145    1   22   82    0    0 1732    1    7]\n",
      " [   5   71    7    3   18    0    0    5  692   12]\n",
      " [   5   70    0   11   12    0    0   25    1 1910]]\n",
      "\n",
      "Classifier: MLP, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.92      0.89      0.91       759\n",
      "          平板       0.73      0.77      0.75      1998\n",
      "          手机       0.81      0.76      0.78       482\n",
      "          水果       0.85      0.84      0.84      1936\n",
      "         洗发水       0.78      0.79      0.78      2008\n",
      "         热水器       0.55      0.45      0.50       117\n",
      "          蒙牛       1.00      0.99      0.99       409\n",
      "          衣服       0.84      0.86      0.85      1999\n",
      "         计算机       0.92      0.85      0.88       813\n",
      "          酒店       0.97      0.95      0.96      2034\n",
      "\n",
      "    accuracy                           0.84     12555\n",
      "   macro avg       0.83      0.81      0.82     12555\n",
      "weighted avg       0.84      0.84      0.84     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 677   15    1   22   18    1    0   14    3    8]\n",
      " [  12 1546   44   58  174    9    0  115   29   11]\n",
      " [   5   70  364    3    7    1    0   11   15    6]\n",
      " [  11   96    3 1619  130    7    0   60    2    8]\n",
      " [  12  170    7  121 1583   10    0   86    6   13]\n",
      " [   0   36    1    4   12   53    0    9    1    1]\n",
      " [   0    0    0    2    1    0  404    1    0    1]\n",
      " [   3  116    8   48   79   14    0 1716    2   13]\n",
      " [   8   56   19   10   11    1    1   11  688    8]\n",
      " [   4   24    5   16   26    1    0   19    5 1934]]\n",
      "\n",
      "RESULTS\n",
      "Classifier: MultinomialNB, Feature Extraction: CountVectorizer,: 0.87\n",
      "Classifier: DecisionTree, Feature Extraction: CountVectorizer,: 0.75\n",
      "Classifier: RandomForest, Feature Extraction: CountVectorizer,: 0.83\n",
      "Classifier: SVM, Feature Extraction: CountVectorizer,: 0.83\n",
      "Classifier: MLP, Feature Extraction: CountVectorizer,: 0.84\n",
      "\n",
      "Classification Finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import jieba  \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 讀取CSV文件\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "# 特徵提取 - 使用CountVectorizer模型 \n",
    "def count_vectorizer(X_train, X_test):\n",
    "    vectorizer = CountVectorizer(analyzer='word')  # 使用word單詞級別的特徵\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    return X_train_vectorized, X_test_vectorized\n",
    "\n",
    "\n",
    "# 使用jieba進行分詞\n",
    "def jieba_tokenize(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "# 初始化不同的分類器\n",
    "def initialize_classifiers():\n",
    "    classifiers = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(),\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"MLP\": MLPClassifier()\n",
    "    }\n",
    "    return classifiers\n",
    "\n",
    "# 訓練、評估\n",
    "def train_and_evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)  #計算混淆矩陣\n",
    "    return {'accuracy': accuracy, 'classification_report': classification_rep, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'simplified_dataset/simplified_raw_data.csv'\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # 將NaN值替換為空字串\n",
    "    data['review'] = data['review'].fillna('')\n",
    "    \n",
    "    X = data['review']\n",
    "    y = data['cat']\n",
    "    \n",
    "    classifiers = initialize_classifiers()\n",
    "    feature_extraction_methods = {\n",
    "        \"CountVectorizer\": count_vectorizer\n",
    "    }\n",
    "    \n",
    "    # 初始化结果字典\n",
    "    results_dict = {}\n",
    "\n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        for method_name, feature_extractor in feature_extraction_methods.items():\n",
    "            print(f\"Classifier: {clf_name}, Feature Extraction: {method_name}\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # 使用jieba分词处理文本数据\n",
    "            X_train_tokenized = X_train.apply(jieba_tokenize)\n",
    "            X_test_tokenized = X_test.apply(jieba_tokenize)\n",
    "            \n",
    "            X_train_vectorized, X_test_vectorized = feature_extractor(X_train_tokenized, X_test_tokenized)\n",
    "            results = train_and_evaluate_classifier(classifier, X_train_vectorized, X_test_vectorized, y_train, y_test)\n",
    "\n",
    "            # 儲存结果到字典\n",
    "            results_dict[(clf_name, method_name)] = results\n",
    "\n",
    "            print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "            print(f\"Classification Report:\\n{results['classification_report']}\\n\")\n",
    "            print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\\n\")\n",
    "\n",
    "    # 統整結果\n",
    "    print(\"RESULTS\")\n",
    "    for(clf_name, method_name), results in results_dict.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction: {method_name},: {results['accuracy']:.2f}\")\n",
    "\n",
    "    print(\"\\nClassification Finish\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b1f24",
   "metadata": {},
   "source": [
    "# TF-IDF-word freqency\n",
    "\n",
    "TF-IDF 結合了詞頻（Term Frequency，TF）和逆文檔頻率（Inverse Document Frequency，IDF）。TF 表示詞彙在文檔中的出現頻率，而 IDF 衡量了詞彙在整個文集中的重要性。TfidfVectorizer 計算 TF-IDF 值，並將其轉化為特徵向量。\n",
    "\n",
    "classifier : MultinomialNB , DecisionTree , RandomForest , SVM , MLP\n",
    "\n",
    "dataset : train - 80 percentage , test - 20 percentage\n",
    "\n",
    "condition ：需要先用jieba切詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7500e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MultinomialNB, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.82\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.96      0.80      0.87       759\n",
      "          平板       0.64      0.81      0.72      1998\n",
      "          手机       0.99      0.32      0.49       482\n",
      "          水果       0.85      0.89      0.87      1936\n",
      "         洗发水       0.78      0.85      0.81      2008\n",
      "         热水器       0.00      0.00      0.00       117\n",
      "          蒙牛       1.00      0.60      0.75       409\n",
      "          衣服       0.86      0.88      0.87      1999\n",
      "         计算机       0.98      0.62      0.76       813\n",
      "          酒店       0.91      0.99      0.95      2034\n",
      "\n",
      "    accuracy                           0.82     12555\n",
      "   macro avg       0.80      0.68      0.71     12555\n",
      "weighted avg       0.83      0.82      0.81     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 608   52    0   28   27    0    0    7    0   37]\n",
      " [   1 1622    1   50  178    0    0  123    0   23]\n",
      " [   0  279  156    6    4    0    0    9    9   19]\n",
      " [   4   46    0 1720  111    0    0   42    0   13]\n",
      " [   2  127    0   93 1703    0    0   65    0   18]\n",
      " [   1   44    0    9   29    0    0   23    1   10]\n",
      " [  16   25    0   47   39    0  245    7    0   30]\n",
      " [   1   78    0   47   85    0    0 1767    0   21]\n",
      " [   0  247    0    7   16    0    0    6  501   36]\n",
      " [   0    4    0   12    3    0    0    5    0 2010]]\n",
      "\n",
      "Classifier: DecisionTree, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.82      0.83      0.82       759\n",
      "          平板       0.61      0.63      0.62      1998\n",
      "          手机       0.70      0.58      0.63       482\n",
      "          水果       0.78      0.78      0.78      1936\n",
      "         洗发水       0.68      0.71      0.69      2008\n",
      "         热水器       0.57      0.38      0.46       117\n",
      "          蒙牛       1.00      0.99      1.00       409\n",
      "          衣服       0.76      0.79      0.77      1999\n",
      "         计算机       0.73      0.70      0.72       813\n",
      "          酒店       0.95      0.92      0.93      2034\n",
      "\n",
      "    accuracy                           0.76     12555\n",
      "   macro avg       0.76      0.73      0.74     12555\n",
      "weighted avg       0.76      0.76      0.76     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 631   35    4   18   23    1    0   27   12    8]\n",
      " [  22 1258   67   99  262   14    0  171   86   19]\n",
      " [   7  111  278    6   13    0    0   18   46    3]\n",
      " [  23  122    2 1507  175    1    0   77   14   15]\n",
      " [  26  205    7  169 1420    5    0  131   29   16]\n",
      " [   1   34    1    5   15   45    0   13    1    2]\n",
      " [   0    1    0    1    0    0  406    0    0    1]\n",
      " [  32  155    4   74  126   10    0 1573   12   13]\n",
      " [  14  108   32   16   32    3    0   24  571   13]\n",
      " [  18   48    2   26   24    0    0   40   12 1864]]\n",
      "\n",
      "Classifier: RandomForest, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.97      0.87      0.92       759\n",
      "          平板       0.69      0.77      0.73      1998\n",
      "          手机       0.93      0.65      0.76       482\n",
      "          水果       0.88      0.83      0.86      1936\n",
      "         洗发水       0.75      0.82      0.78      2008\n",
      "         热水器       0.91      0.34      0.50       117\n",
      "          蒙牛       1.00      1.00      1.00       409\n",
      "          衣服       0.82      0.88      0.85      1999\n",
      "         计算机       0.95      0.78      0.86       813\n",
      "          酒店       0.97      0.96      0.96      2034\n",
      "\n",
      "    accuracy                           0.84     12555\n",
      "   macro avg       0.89      0.79      0.82     12555\n",
      "weighted avg       0.85      0.84      0.84     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 658   31    0   13   26    0    0   22    1    8]\n",
      " [   2 1537   14   51  232    0    0  137   18    7]\n",
      " [   5  129  312    6    4    0    0   13    9    4]\n",
      " [   6   85    0 1607  151    0    0   77    0   10]\n",
      " [   2  157    1   84 1650    3    0   97    0   14]\n",
      " [   0   34    0    2   20   40    0   17    1    3]\n",
      " [   0    1    0    0    0    0  407    0    0    1]\n",
      " [   2  108    1   33   86    1    1 1761    0    6]\n",
      " [   2  106    8   14   24    0    0   15  634   10]\n",
      " [   2   38    1   11   10    0    0   19    1 1952]]\n",
      "\n",
      "Classifier: SVM, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.97      0.92      0.94       759\n",
      "          平板       0.73      0.82      0.77      1998\n",
      "          手机       0.93      0.74      0.82       482\n",
      "          水果       0.93      0.85      0.89      1936\n",
      "         洗发水       0.78      0.86      0.81      2008\n",
      "         热水器       0.98      0.37      0.53       117\n",
      "          蒙牛       1.00      0.99      1.00       409\n",
      "          衣服       0.87      0.89      0.88      1999\n",
      "         计算机       0.96      0.86      0.91       813\n",
      "          酒店       0.99      0.96      0.98      2034\n",
      "\n",
      "    accuracy                           0.87     12555\n",
      "   macro avg       0.91      0.83      0.85     12555\n",
      "weighted avg       0.88      0.87      0.87     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 698   31    0    5   14    0    0   10    1    0]\n",
      " [   2 1642   18   23  201    0    0   99   12    1]\n",
      " [   1   93  356    2    3    0    0    8   17    2]\n",
      " [   7   89    0 1639  145    0    0   53    0    3]\n",
      " [   7  152    0   53 1723    0    0   68    0    5]\n",
      " [   0   37    0    1   20   43    0   15    0    1]\n",
      " [   1    1    0    1    0    0  406    0    0    0]\n",
      " [   1   96    2   23   89    1    0 1784    1    2]\n",
      " [   3   79    5    4   15    0    0    6  701    0]\n",
      " [   3   38    1   11   12    0    0   17    0 1952]]\n",
      "\n",
      "Classifier: MLP, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.85\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.93      0.91      0.92       759\n",
      "          平板       0.75      0.78      0.77      1998\n",
      "          手机       0.84      0.79      0.81       482\n",
      "          水果       0.83      0.84      0.84      1936\n",
      "         洗发水       0.77      0.79      0.78      2008\n",
      "         热水器       0.57      0.47      0.51       117\n",
      "          蒙牛       1.00      0.99      0.99       409\n",
      "          衣服       0.85      0.85      0.85      1999\n",
      "         计算机       0.91      0.87      0.89       813\n",
      "          酒店       0.98      0.95      0.97      2034\n",
      "\n",
      "    accuracy                           0.85     12555\n",
      "   macro avg       0.84      0.82      0.83     12555\n",
      "weighted avg       0.85      0.85      0.85     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 688   21    2   22   14    1    0    8    2    1]\n",
      " [   8 1557   33   67  192   10    0   99   24    8]\n",
      " [   4   58  379    3    5    2    0    9   19    3]\n",
      " [  11   85    5 1635  121    4    0   65    5    5]\n",
      " [  13  150    6  149 1581   11    0   86    4    8]\n",
      " [   1   27    2    4   14   55    0   11    2    1]\n",
      " [   1    0    0    2    2    0  404    0    0    0]\n",
      " [   5   98    4   56  104   12    0 1702    7   11]\n",
      " [   3   47   17    9    9    2    0   14  708    4]\n",
      " [   5   23    4   23   21    0    0   13    3 1942]]\n",
      "\n",
      "RESULTS\n",
      "Classifier: MultinomialNB, Feature Extraction: TfidfVectorizer,: 0.82\n",
      "Classifier: DecisionTree, Feature Extraction: TfidfVectorizer,: 0.76\n",
      "Classifier: RandomForest, Feature Extraction: TfidfVectorizer,: 0.84\n",
      "Classifier: SVM, Feature Extraction: TfidfVectorizer,: 0.87\n",
      "Classifier: MLP, Feature Extraction: TfidfVectorizer,: 0.85\n",
      "\n",
      "Classification Finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import jieba  \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 讀取CSV文件\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "# 特徵提取 - TF-IDF模型\n",
    "def tfidf_vectorizer(X_train, X_test):\n",
    "    vectorizer = TfidfVectorizer(analyzer='word')   # 使用word單詞級別的特徵\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "# 使用jieba进行分词\n",
    "def jieba_tokenize(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "# 初始化不同的分類器\n",
    "def initialize_classifiers():\n",
    "    classifiers = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(),\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"MLP\": MLPClassifier()\n",
    "    }\n",
    "    return classifiers\n",
    "\n",
    "# 訓練、評估\n",
    "def train_and_evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)  #計算混淆矩陣\n",
    "    return {'accuracy': accuracy, 'classification_report': classification_rep, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'simplified_dataset/simplified_raw_data.csv'\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # 將NaN值替換為空字串\n",
    "    data['review'] = data['review'].fillna('')\n",
    "    \n",
    "    X = data['review']\n",
    "    y = data['cat']\n",
    "    \n",
    "    classifiers = initialize_classifiers()\n",
    "    feature_extraction_methods = {\n",
    "        \"TfidfVectorizer\": tfidf_vectorizer\n",
    "    }\n",
    "    \n",
    "    # 初始化结果字典\n",
    "    results_dict = {}\n",
    "\n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        for method_name, feature_extractor in feature_extraction_methods.items():\n",
    "            print(f\"Classifier: {clf_name}, Feature Extraction: {method_name}\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # 使用jieba分词处理文本数据\n",
    "            X_train_tokenized = X_train.apply(jieba_tokenize)\n",
    "            X_test_tokenized = X_test.apply(jieba_tokenize)\n",
    "            \n",
    "            X_train_vectorized, X_test_vectorized = feature_extractor(X_train_tokenized, X_test_tokenized)\n",
    "            results = train_and_evaluate_classifier(classifier, X_train_vectorized, X_test_vectorized, y_train, y_test)\n",
    "\n",
    "            # 儲存结果到字典\n",
    "            results_dict[(clf_name, method_name)] = results\n",
    "\n",
    "            print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "            print(f\"Classification Report:\\n{results['classification_report']}\\n\")\n",
    "            print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\\n\")\n",
    "\n",
    "    # 統整結果\n",
    "    print(\"RESULTS\")\n",
    "    for(clf_name, method_name), results in results_dict.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction: {method_name},: {results['accuracy']:.2f}\")\n",
    "\n",
    "    print(\"\\nClassification Finish\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803727d",
   "metadata": {},
   "source": [
    "# TF-IDF-single word\n",
    "\n",
    "TF-IDF 結合了詞頻（Term Frequency，TF）和逆文檔頻率（Inverse Document Frequency，IDF）。TF 表示詞彙在文檔中的出現頻率，而 IDF 衡量了詞彙在整個文集中的重要性。TfidfVectorizer 計算 TF-IDF 值，並將其轉化為特徵向量。\n",
    "\n",
    "classifier : MultinomialNB , DecisionTree , RandomForest , SVM , MLP\n",
    "\n",
    "dataset : train - 80 percentage , test - 20 percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ba9570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MultinomialNB, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.82\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.95      0.81      0.88       759\n",
      "          平板       0.63      0.78      0.70      1998\n",
      "          手机       0.98      0.34      0.50       482\n",
      "          水果       0.88      0.88      0.88      1936\n",
      "         洗发水       0.77      0.85      0.81      2008\n",
      "         热水器       0.00      0.00      0.00       117\n",
      "          蒙牛       0.99      0.80      0.88       409\n",
      "          衣服       0.85      0.87      0.86      1999\n",
      "         计算机       0.86      0.64      0.74       813\n",
      "          酒店       0.91      0.98      0.94      2034\n",
      "\n",
      "    accuracy                           0.82     12555\n",
      "   macro avg       0.78      0.69      0.72     12555\n",
      "weighted avg       0.83      0.82      0.82     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 618   73    0    9   17    0    0    9    2   31]\n",
      " [   3 1565    3   45  217    0    1  125   15   24]\n",
      " [   4  220  162    3    4    0    0    9   44   36]\n",
      " [   4   66    0 1695  106    0    0   51    3   11]\n",
      " [   4  149    0   71 1699    0    1   64    5   15]\n",
      " [   0   36    0   12   34    0    0   20    5   10]\n",
      " [  15   16    0   23   13    0  326    3    2   11]\n",
      " [   1  101    0   52   82    0    0 1741    3   19]\n",
      " [   0  223    1   11   15    0    0    7  524   32]\n",
      " [   0   18    0    5    6    0    0   11    8 1986]]\n",
      "\n",
      "Feature names: [' ' '!' '\"' ... '～' '￣' '￥']\n",
      "Classifier: DecisionTree, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.86      0.82      0.84       759\n",
      "          平板       0.63      0.64      0.64      1998\n",
      "          手机       0.57      0.55      0.56       482\n",
      "          水果       0.83      0.84      0.84      1936\n",
      "         洗发水       0.71      0.72      0.71      2008\n",
      "         热水器       0.40      0.37      0.38       117\n",
      "          蒙牛       1.00      1.00      1.00       409\n",
      "          衣服       0.82      0.82      0.82      1999\n",
      "         计算机       0.69      0.67      0.68       813\n",
      "          酒店       0.93      0.92      0.93      2034\n",
      "\n",
      "    accuracy                           0.78     12555\n",
      "   macro avg       0.74      0.74      0.74     12555\n",
      "weighted avg       0.78      0.78      0.78     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 626   30    6   21   18    0    1   21   13   23]\n",
      " [  29 1279   98   72  240   22    0  122  107   29]\n",
      " [   7  117  267    6   16    2    0   13   48    6]\n",
      " [  11   92    4 1629  108    6    0   60    9   17]\n",
      " [  12  223   16  137 1450   15    0   99   32   24]\n",
      " [   1   23    4    7   28   43    0    6    4    1]\n",
      " [   1    0    0    0    0    0  407    0    1    0]\n",
      " [   8  119   15   59  108   13    0 1636   14   27]\n",
      " [  13  108   43   16   53    4    0   16  547   13]\n",
      " [  16   35   12   17   27    2    0   29   20 1876]]\n",
      "\n",
      "Feature names: [' ' '!' '\"' ... '～' '￣' '￥']\n",
      "Classifier: RandomForest, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.85\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.96      0.89      0.92       759\n",
      "          平板       0.71      0.79      0.75      1998\n",
      "          手机       0.95      0.60      0.73       482\n",
      "          水果       0.91      0.87      0.89      1936\n",
      "         洗发水       0.76      0.84      0.80      2008\n",
      "         热水器       1.00      0.23      0.38       117\n",
      "          蒙牛       0.99      1.00      0.99       409\n",
      "          衣服       0.85      0.90      0.87      1999\n",
      "         计算机       0.90      0.76      0.83       813\n",
      "          酒店       0.97      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.85     12555\n",
      "   macro avg       0.90      0.78      0.81     12555\n",
      "weighted avg       0.86      0.85      0.85     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 672   21    0    9   27    0    0   17    5    8]\n",
      " [   8 1575    8   42  214    0    0  114   27   10]\n",
      " [   3  138  287    7    3    0    0   13   30    1]\n",
      " [   5   58    0 1688  125    0    1   55    1    3]\n",
      " [   3  161    1   60 1690    0    2   79    1   11]\n",
      " [   0   43    0    5   27   27    0    9    2    4]\n",
      " [   0    0    0    0    0    0  407    1    0    1]\n",
      " [   2   78    0   25   92    0    2 1791    0    9]\n",
      " [   5  111    5   14   38    0    0   13  620    7]\n",
      " [   3   21    0    8   13    0    1   24    1 1963]]\n",
      "\n",
      "Feature names: [' ' '!' '\"' ... '～' '￣' '￥']\n",
      "Classifier: SVM, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.95      0.94      0.95       759\n",
      "          平板       0.76      0.82      0.79      1998\n",
      "          手机       0.92      0.80      0.86       482\n",
      "          水果       0.95      0.86      0.91      1936\n",
      "         洗发水       0.80      0.88      0.84      2008\n",
      "         热水器       0.98      0.39      0.56       117\n",
      "          蒙牛       0.99      0.99      0.99       409\n",
      "          衣服       0.88      0.92      0.90      1999\n",
      "         计算机       0.93      0.87      0.90       813\n",
      "          酒店       0.99      0.97      0.98      2034\n",
      "\n",
      "    accuracy                           0.89     12555\n",
      "   macro avg       0.92      0.84      0.87     12555\n",
      "weighted avg       0.89      0.89      0.89     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 717   19    1    1   11    0    0    4    4    2]\n",
      " [   9 1641   17   20  185    0    1  104   21    0]\n",
      " [   4   66  386    2    2    0    0    7   15    0]\n",
      " [   8   73    0 1673  128    0    1   48    2    3]\n",
      " [   8  143    0   33 1758    0    0   56    7    3]\n",
      " [   0   40    0    0   20   46    0    8    1    2]\n",
      " [   0    0    0    2    1    0  405    0    0    1]\n",
      " [   1   78    2   17   63    1    1 1835    1    0]\n",
      " [   3   72   11    3   15    0    0    2  704    3]\n",
      " [   3   18    3    7    9    0    1   14    4 1975]]\n",
      "\n",
      "Feature names: [' ' '!' '\"' ... '～' '￣' '￥']\n",
      "Classifier: MLP, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.93      0.94      0.93       759\n",
      "          平板       0.78      0.78      0.78      1998\n",
      "          手机       0.82      0.81      0.82       482\n",
      "          水果       0.90      0.88      0.89      1936\n",
      "         洗发水       0.81      0.82      0.82      2008\n",
      "         热水器       0.66      0.57      0.61       117\n",
      "          蒙牛       1.00      0.98      0.99       409\n",
      "          衣服       0.86      0.89      0.87      1999\n",
      "         计算机       0.88      0.86      0.87       813\n",
      "          酒店       0.98      0.96      0.97      2034\n",
      "\n",
      "    accuracy                           0.87     12555\n",
      "   macro avg       0.86      0.85      0.85     12555\n",
      "weighted avg       0.87      0.87      0.87     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 713    6    7    4   10    0    0    8    5    6]\n",
      " [   8 1558   28   53  171   13    0  121   40    6]\n",
      " [   3   49  392    3    3    1    0    5   21    5]\n",
      " [  10   65    2 1703   92    2    0   50    7    5]\n",
      " [  10  154    6   76 1655    8    2   81    9    7]\n",
      " [   0   24    0    3   14   67    0    6    2    1]\n",
      " [   2    0    0    3    3    0  400    1    0    0]\n",
      " [   3   79    9   34   74    8    0 1781    3    8]\n",
      " [  11   47   28    3   15    2    0    8  697    2]\n",
      " [  10   13    4   13   12    1    0   16    8 1957]]\n",
      "\n",
      "Feature names: [' ' '!' '\"' ... '～' '￣' '￥']\n",
      "RESULTS\n",
      "Classifier: MultinomialNB, Feature Extraction: TfidfVectorizer,: 0.82\n",
      "Classifier: DecisionTree, Feature Extraction: TfidfVectorizer,: 0.78\n",
      "Classifier: RandomForest, Feature Extraction: TfidfVectorizer,: 0.85\n",
      "Classifier: SVM, Feature Extraction: TfidfVectorizer,: 0.89\n",
      "Classifier: MLP, Feature Extraction: TfidfVectorizer,: 0.87\n",
      "\n",
      "Classification Finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import jieba  \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 讀取CSV文件\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# 特徵提取 - 使用TfidfVectorizer模型 \n",
    "def tfidf_vectorizer(X_train, X_test):\n",
    "    vectorizer = TfidfVectorizer(analyzer='char', use_idf=True)  # 使用字符级别的TF-IDF\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    feature_names = vectorizer.get_feature_names_out()  # 获取特征名称\n",
    "    return X_train_tfidf, X_test_tfidf, feature_names\n",
    "\n",
    "# 使用jieba进行分词\n",
    "def jieba_tokenize(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "# 初始化不同的分類器\n",
    "def initialize_classifiers():\n",
    "    classifiers = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(),\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"MLP\": MLPClassifier()\n",
    "    }\n",
    "    return classifiers\n",
    "\n",
    "# 訓練、評估\n",
    "def train_and_evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)  #計算混淆矩陣\n",
    "    return {'accuracy': accuracy, 'classification_report': classification_rep, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'simplified_dataset/simplified_raw_data.csv'\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # 將NaN值替換為空字串\n",
    "    data['review'] = data['review'].fillna('')\n",
    "    \n",
    "    X = data['review']\n",
    "    y = data['cat']\n",
    "    \n",
    "    classifiers = initialize_classifiers()\n",
    "    feature_extraction_methods = {\n",
    "        \"TfidfVectorizer\": tfidf_vectorizer\n",
    "    }\n",
    "    \n",
    "    # 初始化结果字典\n",
    "    results_dict = {}\n",
    "\n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        for method_name, feature_extractor in feature_extraction_methods.items():\n",
    "            print(f\"Classifier: {clf_name}, Feature Extraction: {method_name}\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # 使用jieba分词处理文本数据\n",
    "            X_train_tokenized = X_train.apply(jieba_tokenize)\n",
    "            X_test_tokenized = X_test.apply(jieba_tokenize)\n",
    "            \n",
    "            X_train_vectorized, X_test_vectorized, feature_names = feature_extractor(X_train_tokenized, X_test_tokenized)\n",
    "            results = train_and_evaluate_classifier(classifier, X_train_vectorized, X_test_vectorized, y_train, y_test)\n",
    "\n",
    "            # 儲存结果到字典\n",
    "            results_dict[(clf_name, method_name)] = results\n",
    "\n",
    "            print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "            print(f\"Classification Report:\\n{results['classification_report']}\\n\")\n",
    "            print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\\n\")\n",
    "            \n",
    "            # 打印特征名称\n",
    "            print(\"Feature names:\", feature_names)\n",
    "\n",
    "    # 統整結果\n",
    "    print(\"RESULTS\")\n",
    "    for(clf_name, method_name), results in results_dict.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction: {method_name},: {results['accuracy']:.2f}\")\n",
    "\n",
    "    print(\"\\nClassification Finish\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded2045",
   "metadata": {},
   "source": [
    "# 不看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b9acc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MultinomialNB, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.85\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.91      0.92      0.92       759\n",
      "          平板       0.76      0.70      0.73      1998\n",
      "          手机       0.80      0.77      0.78       482\n",
      "          水果       0.90      0.87      0.88      1936\n",
      "         洗发水       0.78      0.85      0.81      2008\n",
      "         热水器       0.89      0.36      0.51       117\n",
      "          蒙牛       0.94      0.99      0.97       409\n",
      "          衣服       0.84      0.88      0.86      1999\n",
      "         计算机       0.82      0.84      0.83       813\n",
      "          酒店       0.97      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.85     12555\n",
      "   macro avg       0.86      0.81      0.83     12555\n",
      "weighted avg       0.85      0.85      0.85     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 699   26    9    2   11    0    2    1    6    3]\n",
      " [  15 1394   48   53  240    0    7  154   79    8]\n",
      " [   6   64  373    5    2    0    0    8   20    4]\n",
      " [  14   52    4 1683  111    2    3   52   10    5]\n",
      " [  10  120    6   68 1697    2    7   69   16   13]\n",
      " [   0   14    0   11   20   42    1   18    8    3]\n",
      " [   2    0    0    0    0    0  406    0    0    1]\n",
      " [   8   86    4   37   90    0    5 1754    4   11]\n",
      " [   4   74   22    6   12    0    0    3  685    7]\n",
      " [   7   15    3    6    6    1    1   20   12 1963]]\n",
      "\n",
      "Classifier: MultinomialNB, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.98      0.05      0.10       759\n",
      "          平板       0.46      0.39      0.42      1998\n",
      "          手机       1.00      0.03      0.06       482\n",
      "          水果       0.29      0.77      0.42      1936\n",
      "         洗发水       0.59      0.47      0.52      2008\n",
      "         热水器       0.00      0.00      0.00       117\n",
      "          蒙牛       1.00      0.19      0.32       409\n",
      "          衣服       0.58      0.61      0.60      1999\n",
      "         计算机       0.92      0.12      0.21       813\n",
      "          酒店       0.74      0.64      0.68      2034\n",
      "\n",
      "    accuracy                           0.47     12555\n",
      "   macro avg       0.66      0.33      0.33     12555\n",
      "weighted avg       0.61      0.47      0.45     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  40   59    0  419   40    0    0   66    0  135]\n",
      " [   0  778    0  671  241    0    0  254    2   52]\n",
      " [   0  110   14  210   17    0    0   65    4   62]\n",
      " [   0  127    0 1500  149    0    0  121    0   39]\n",
      " [   0  203    0  638  940    0    0  188    1   38]\n",
      " [   0   23    0   39   26    0    0   25    0    4]\n",
      " [   1   18    0  254    8    0   79   24    0   25]\n",
      " [   0  115    0  519  116    0    0 1220    0   29]\n",
      " [   0  163    0  365   38    0    0   73   94   80]\n",
      " [   0   88    0  559   31    0    0   63    1 1292]]\n",
      "\n",
      "Classifier: DecisionTree, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.84      0.79      0.82       759\n",
      "          平板       0.64      0.66      0.65      1998\n",
      "          手机       0.61      0.58      0.59       482\n",
      "          水果       0.82      0.84      0.83      1936\n",
      "         洗发水       0.73      0.71      0.72      2008\n",
      "         热水器       0.36      0.37      0.36       117\n",
      "          蒙牛       1.00      0.99      0.99       409\n",
      "          衣服       0.80      0.83      0.82      1999\n",
      "         计算机       0.70      0.66      0.68       813\n",
      "          酒店       0.94      0.92      0.93      2034\n",
      "\n",
      "    accuracy                           0.78     12555\n",
      "   macro avg       0.74      0.74      0.74     12555\n",
      "weighted avg       0.78      0.78      0.78     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 603   31   11   18   27    1    0   28   20   20]\n",
      " [  22 1326   91   87  212   20    0  122   96   22]\n",
      " [  11  111  280    4   11    2    0   17   40    6]\n",
      " [  10   88    5 1618  112   10    0   71   11   11]\n",
      " [  23  207    7  139 1434   24    0  112   34   28]\n",
      " [   1   30    6    6   16   43    0    6    7    2]\n",
      " [   0    0    0    2    0    0  406    0    0    1]\n",
      " [  18  119    8   51  102    7    0 1662   10   22]\n",
      " [  14  122   47   29   29    5    0   16  539   12]\n",
      " [  18   33    6   15   24    7    2   32   16 1881]]\n",
      "\n",
      "Classifier: DecisionTree, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.39\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.54      0.15      0.23       759\n",
      "          平板       0.21      0.71      0.32      1998\n",
      "          手机       0.46      0.19      0.27       482\n",
      "          水果       0.62      0.37      0.46      1936\n",
      "         洗发水       0.50      0.28      0.36      2008\n",
      "         热水器       0.16      0.14      0.15       117\n",
      "          蒙牛       0.82      0.33      0.47       409\n",
      "          衣服       0.58      0.43      0.49      1999\n",
      "         计算机       0.61      0.20      0.30       813\n",
      "          酒店       0.81      0.40      0.54      2034\n",
      "\n",
      "    accuracy                           0.39     12555\n",
      "   macro avg       0.53      0.32      0.36     12555\n",
      "weighted avg       0.55      0.39      0.41     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 111  492   11   36   19    0    8   30   17   35]\n",
      " [  13 1415   33   93  176   23    2  185   24   34]\n",
      " [   7  301   90   13   10    0    1   22   17   21]\n",
      " [  10  917    4  711  132   10    3  125    3   21]\n",
      " [  11 1094    2  112  572   21    4  159    9   24]\n",
      " [   0   71    2    5   12   16    0    9    0    2]\n",
      " [   3  242    2    9    6    0  133    6    0    8]\n",
      " [   6  839    7   90  143   22    4  854    6   28]\n",
      " [  10  501   29   29   32    2    0   25  165   20]\n",
      " [  33  974   14   54   38    4    7   62   29  819]]\n",
      "\n",
      "Classifier: RandomForest, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.98      0.88      0.93       759\n",
      "          平板       0.71      0.82      0.76      1998\n",
      "          手机       0.96      0.63      0.76       482\n",
      "          水果       0.91      0.88      0.89      1936\n",
      "         洗发水       0.78      0.85      0.81      2008\n",
      "         热水器       0.92      0.28      0.43       117\n",
      "          蒙牛       0.99      1.00      0.99       409\n",
      "          衣服       0.86      0.90      0.88      1999\n",
      "         计算机       0.94      0.74      0.83       813\n",
      "          酒店       0.98      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.86     12555\n",
      "   macro avg       0.90      0.79      0.82     12555\n",
      "weighted avg       0.87      0.86      0.86     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 669   27    0   10   27    0    0   14    4    8]\n",
      " [   3 1631    8   35  192    1    0  106   12   10]\n",
      " [   1  130  302    5    4    0    0   15   23    2]\n",
      " [   3   68    1 1696  114    1    1   49    0    3]\n",
      " [   1  152    0   63 1705    1    2   75    1    8]\n",
      " [   0   42    0    2   27   33    0   11    0    2]\n",
      " [   0    0    0    0    0    0  409    0    0    0]\n",
      " [   2   95    0   29   67    0    1 1793    0   12]\n",
      " [   5  140    3   15   27    0    0   15  603    5]\n",
      " [   1   19    1   13   17    0    1   17    0 1965]]\n",
      "\n",
      "Classifier: RandomForest, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.66      0.16      0.26       759\n",
      "          平板       0.22      0.72      0.34      1998\n",
      "          手机       0.54      0.18      0.27       482\n",
      "          水果       0.68      0.39      0.50      1936\n",
      "         洗发水       0.54      0.36      0.44      2008\n",
      "         热水器       0.15      0.13      0.14       117\n",
      "          蒙牛       0.84      0.34      0.49       409\n",
      "          衣服       0.61      0.48      0.54      1999\n",
      "         计算机       0.69      0.22      0.33       813\n",
      "          酒店       0.85      0.45      0.59      2034\n",
      "\n",
      "    accuracy                           0.43     12555\n",
      "   macro avg       0.58      0.34      0.39     12555\n",
      "weighted avg       0.59      0.43      0.45     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 121  473    8   31   35    0    5   39   16   31]\n",
      " [   9 1445   20   75  197   21    3  177   22   29]\n",
      " [   7  287   88   14   22    2    0   22   18   22]\n",
      " [   5  868    1  761  140   15    5  116    4   21]\n",
      " [   8  958    4   99  731   22    5  165    2   14]\n",
      " [   1   72    2    2   14   15    0    9    0    2]\n",
      " [   2  240    1    6    6    0  141    6    0    7]\n",
      " [   6  797    7   55  121   17    3  964    3   26]\n",
      " [   9  496   26   26   35    3    1   27  175   15]\n",
      " [  15  895    7   56   49    7    4   66   15  920]]\n",
      "\n",
      "Classifier: SVM, Feature Extraction: CountVectorizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.96      0.88      0.92       759\n",
      "          平板       0.71      0.82      0.76      1998\n",
      "          手机       0.94      0.65      0.77       482\n",
      "          水果       0.94      0.85      0.89      1936\n",
      "         洗发水       0.79      0.83      0.81      2008\n",
      "         热水器       0.97      0.32      0.48       117\n",
      "          蒙牛       1.00      0.99      0.99       409\n",
      "          衣服       0.85      0.90      0.87      1999\n",
      "         计算机       0.92      0.83      0.87       813\n",
      "          酒店       0.92      0.95      0.94      2034\n",
      "\n",
      "    accuracy                           0.86     12555\n",
      "   macro avg       0.90      0.80      0.83     12555\n",
      "weighted avg       0.87      0.86      0.86     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 668   25    0    1   14    0    0   14    4   33]\n",
      " [   4 1629    7   24  165    0    1  119   28   21]\n",
      " [   4   97  313    3    2    0    0   13   13   37]\n",
      " [   2   82    0 1636  139    0    0   56    2   19]\n",
      " [   7  185    1   35 1675    0    0   80    5   20]\n",
      " [   0   41    0    1   22   37    0   10    2    4]\n",
      " [   0    1    0    1    0    0  405    0    0    2]\n",
      " [   2   95    1   17   64    0    1 1808    2    9]\n",
      " [   6   80   10    5   19    0    0    7  674   12]\n",
      " [   6   44    1    9    9    1    0   32    3 1929]]\n",
      "\n",
      "Classifier: SVM, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.76      0.11      0.19       759\n",
      "          平板       0.26      0.69      0.38      1998\n",
      "          手机       0.80      0.09      0.16       482\n",
      "          水果       0.69      0.50      0.58      1936\n",
      "         洗发水       0.60      0.44      0.51      2008\n",
      "         热水器       1.00      0.07      0.13       117\n",
      "          蒙牛       0.96      0.28      0.43       409\n",
      "          衣服       0.70      0.53      0.60      1999\n",
      "         计算机       0.66      0.20      0.31       813\n",
      "          酒店       0.56      0.63      0.60      2034\n",
      "\n",
      "    accuracy                           0.48     12555\n",
      "   macro avg       0.70      0.35      0.39     12555\n",
      "weighted avg       0.61      0.48      0.48     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  83  382    1   24   25    0    1   21    9  213]\n",
      " [   3 1384    4   93  217    0    0  160   20  117]\n",
      " [   3  246   43    6   10    0    0   15   18  141]\n",
      " [   2  643    0  974  141    0    1   81    4   90]\n",
      " [   1  778    0  149  883    0    2  114    6   75]\n",
      " [   0   60    1    4   21    8    0   11    0   12]\n",
      " [   6  206    1    7    6    0  114    2    2   65]\n",
      " [   1  626    0   86  109    0    0 1069   11   97]\n",
      " [   5  386    3   16   36    0    0   23  162  182]\n",
      " [   5  617    1   44   27    0    1   42   14 1283]]\n",
      "\n",
      "Classifier: MLP, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.94      0.93      0.93       759\n",
      "          平板       0.77      0.79      0.78      1998\n",
      "          手机       0.82      0.81      0.82       482\n",
      "          水果       0.89      0.88      0.88      1936\n",
      "         洗发水       0.82      0.82      0.82      2008\n",
      "         热水器       0.65      0.56      0.61       117\n",
      "          蒙牛       0.99      0.97      0.98       409\n",
      "          衣服       0.87      0.90      0.88      1999\n",
      "         计算机       0.88      0.85      0.87       813\n",
      "          酒店       0.97      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.87     12555\n",
      "   macro avg       0.86      0.85      0.85     12555\n",
      "weighted avg       0.87      0.87      0.87     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 703   12    8   10    7    0    1    8    4    6]\n",
      " [   9 1587   25   49  152   16    2  104   41   13]\n",
      " [   3   51  389    1    3    2    0    5   23    5]\n",
      " [   6   64    2 1700   95    1    0   58    4    6]\n",
      " [  10  160    4   96 1637    5    0   74   10   12]\n",
      " [   0   28    2    1   10   66    0    5    3    2]\n",
      " [   2    0    0    4    2    0  398    2    0    1]\n",
      " [   1   79    9   34   64    7    0 1797    2    6]\n",
      " [   9   53   27    2   12    3    0    7  693    7]\n",
      " [   8   14    6    9    9    1    0   16    5 1966]]\n",
      "\n",
      "Classifier: MLP, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.51\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.64      0.33      0.44       759\n",
      "          平板       0.26      0.67      0.38      1998\n",
      "          手机       0.61      0.34      0.44       482\n",
      "          水果       0.70      0.52      0.60      1936\n",
      "         洗发水       0.61      0.41      0.49      2008\n",
      "         热水器       0.21      0.19      0.20       117\n",
      "          蒙牛       0.88      0.39      0.54       409\n",
      "          衣服       0.66      0.55      0.60      1999\n",
      "         计算机       0.63      0.43      0.51       813\n",
      "          酒店       0.82      0.61      0.70      2034\n",
      "\n",
      "    accuracy                           0.51     12555\n",
      "   macro avg       0.60      0.44      0.49     12555\n",
      "weighted avg       0.62      0.51      0.53     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 250  375   12   17   24    1    6   19   22   33]\n",
      " [  19 1337   26  112  198   23    0  169   61   53]\n",
      " [  16  206  166    5    7    0    0   18   37   27]\n",
      " [  15  619    5 1012  118    8    2  109   13   35]\n",
      " [  15  770    5  152  815   23    4  166   20   38]\n",
      " [   0   51    1    6   16   22    0   15    0    6]\n",
      " [  15  203    4    6    5    0  161    3    4    8]\n",
      " [  13  614    7   74  111   23    2 1099   21   35]\n",
      " [  12  332   33   12   16    3    6   22  346   31]\n",
      " [  35  597   13   40   31    4    3   50   26 1235]]\n",
      "\n",
      "RESULTS\n",
      "Classifier: MultinomialNB, Feature Extraction: CountVectorizer,: 0.85\n",
      "Classifier: MultinomialNB, Feature Extraction: TfidfVectorizer,: 0.47\n",
      "Classifier: DecisionTree, Feature Extraction: CountVectorizer,: 0.78\n",
      "Classifier: DecisionTree, Feature Extraction: TfidfVectorizer,: 0.39\n",
      "Classifier: RandomForest, Feature Extraction: CountVectorizer,: 0.86\n",
      "Classifier: RandomForest, Feature Extraction: TfidfVectorizer,: 0.43\n",
      "Classifier: SVM, Feature Extraction: CountVectorizer,: 0.86\n",
      "Classifier: SVM, Feature Extraction: TfidfVectorizer,: 0.48\n",
      "Classifier: MLP, Feature Extraction: CountVectorizer,: 0.87\n",
      "Classifier: MLP, Feature Extraction: TfidfVectorizer,: 0.51\n",
      "\n",
      "Classification Finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 讀取CSV文件\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# 特徵提取 - 使用CountVectorizer模型 \n",
    "def count_vectorizer(X_train, X_test):\n",
    "    vectorizer = CountVectorizer(analyzer='char')\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    return X_train_vectorized, X_test_vectorized\n",
    "\n",
    "# 特徵提取 - TF-IDF模型\n",
    "def tfidf_vectorizer(X_train, X_test):\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word')\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "# 初始化不同的分類器\n",
    "def initialize_classifiers():\n",
    "    classifiers = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(),\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"MLP\": MLPClassifier()\n",
    "    }\n",
    "    return classifiers\n",
    "\n",
    "# 訓練、評估\n",
    "def train_and_evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)  #計算混淆矩陣\n",
    "    return {'accuracy': accuracy, 'classification_report': classification_rep, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'simplified_dataset/simplified_raw_data.csv'\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # 將NaN值替換為空字串\n",
    "    data['review'] = data['review'].fillna('')\n",
    "    \n",
    "    X = data['review']\n",
    "    y = data['cat']\n",
    "    \n",
    "    classifiers = initialize_classifiers()\n",
    "    feature_extraction_methods = {\n",
    "        \"CountVectorizer\": count_vectorizer,\n",
    "        \"TfidfVectorizer\": tfidf_vectorizer,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # 初始化结果字典\n",
    "    results_dict = {}\n",
    "\n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        for method_name, feature_extractor in feature_extraction_methods.items():\n",
    "            print(f\"Classifier: {clf_name}, Feature Extraction: {method_name}\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            X_train_vectorized, X_test_vectorized = feature_extractor(X_train, X_test)\n",
    "            results = train_and_evaluate_classifier(classifier, X_train_vectorized, X_test_vectorized, y_train, y_test)\n",
    "\n",
    "            # 儲存结果到字典\n",
    "            results_dict[(clf_name, method_name)] = results\n",
    "\n",
    "            print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "            print(f\"Classification Report:\\n{results['classification_report']}\\n\")\n",
    "            print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # 統整結果\n",
    "    print(\"RESULTS\")\n",
    "    for(clf_name, method_name), results in results_dict.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction: {method_name},: {results['accuracy']:.2f}\")\n",
    "\n",
    "        \n",
    "    print(\"\\nClassification Finish\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e421037",
   "metadata": {},
   "source": [
    "#  不看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d422a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import jieba  # 导入jieba库\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 讀取CSV文件\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# 特徵提取 - 使用CountVectorizer模型 \n",
    "def count_vectorizer(X_train, X_test):\n",
    "    vectorizer = CountVectorizer(analyzer='word')  # 修改为使用单词级别的特征提取\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    return X_train_vectorized, X_test_vectorized\n",
    "\n",
    "# 特徵提取 - TF-IDF模型\n",
    "def tfidf_vectorizer(X_train, X_test):\n",
    "    vectorizer = TfidfVectorizer(analyzer='word')  # 修改为使用单词级别的特征提取\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "# 使用jieba进行分词\n",
    "def jieba_tokenize(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "# 初始化不同的分類器\n",
    "def initialize_classifiers():\n",
    "    classifiers = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(),\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"SVM\": SVC()\n",
    "        #\"MLP\": MLPClassifier()\n",
    "    }\n",
    "    return classifiers\n",
    "\n",
    "# 訓練、評估\n",
    "def train_and_evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)  #計算混淆矩陣\n",
    "    return {'accuracy': accuracy, 'classification_report': classification_rep, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'simplified_dataset/simplified_raw_data.csv'\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # 將NaN值替換為空字串\n",
    "    data['review'] = data['review'].fillna('')\n",
    "    \n",
    "    X = data['review']\n",
    "    y = data['cat']\n",
    "    \n",
    "    classifiers = initialize_classifiers()\n",
    "    feature_extraction_methods = {\n",
    "        \"CountVectorizer\": count_vectorizer,\n",
    "        \"TfidfVectorizer\": tfidf_vectorizer,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # 初始化结果字典\n",
    "    results_dict = {}\n",
    "\n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        for method_name, feature_extractor in feature_extraction_methods.items():\n",
    "            print(f\"Classifier: {clf_name}, Feature Extraction: {method_name}\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # 使用jieba分词处理文本数据\n",
    "            X_train_tokenized = X_train.apply(jieba_tokenize)\n",
    "            X_test_tokenized = X_test.apply(jieba_tokenize)\n",
    "            \n",
    "            X_train_vectorized, X_test_vectorized = feature_extractor(X_train_tokenized, X_test_tokenized)\n",
    "            results = train_and_evaluate_classifier(classifier, X_train_vectorized, X_test_vectorized, y_train, y_test)\n",
    "\n",
    "            # 儲存结果到字典\n",
    "            results_dict[(clf_name, method_name)] = results\n",
    "\n",
    "            print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "            print(f\"Classification Report:\\n{results['classification_report']}\\n\")\n",
    "            print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\\n\")\n",
    "\n",
    "    # 統整結果\n",
    "    print(\"RESULTS\")\n",
    "    for(clf_name, method_name), results in results_dict.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction: {method_name},: {results['accuracy']:.2f}\")\n",
    "\n",
    "    print(\"\\nClassification Finish\")\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
