{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7242cc",
   "metadata": {},
   "source": [
    "# Practice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebc2183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>Category_Index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>书籍</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书籍</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>书籍</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书籍</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62769</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "      <td>我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62770</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9997</td>\n",
       "      <td>0</td>\n",
       "      <td>房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62771</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9998</td>\n",
       "      <td>0</td>\n",
       "      <td>我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62772</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62773</th>\n",
       "      <td>酒店</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62774 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat  Category_Index  label  \\\n",
       "0      书籍               1      1   \n",
       "1      书籍               2      1   \n",
       "2      书籍               3      1   \n",
       "3      书籍               4      1   \n",
       "4      书籍               5      1   \n",
       "...    ..             ...    ...   \n",
       "62769  酒店            9996      0   \n",
       "62770  酒店            9997      0   \n",
       "62771  酒店            9998      0   \n",
       "62772  酒店            9999      0   \n",
       "62773  酒店           10000      0   \n",
       "\n",
       "                                                  review  \n",
       "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...  \n",
       "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...  \n",
       "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...  \n",
       "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...  \n",
       "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...  \n",
       "...                                                  ...  \n",
       "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...  \n",
       "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...  \n",
       "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！  \n",
       "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...  \n",
       "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...  \n",
       "\n",
       "[62774 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 讀取CSV文件\n",
    "data = pd.read_csv('simplified_dataset/simplified_raw_data.csv')  # 替換成你的CSV文件路徑\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771e91f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/32/17fwcjcd1kv9vkdd_3w2k4vw0000gn/T/jieba.cache\n",
      "Loading model cost 0.317 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>Category_Index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>分詞描述</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...</td>\n",
       "      <td>﻿ 做 父母 一定 要 有 刘墉 这样 的 心态 ， 不断 地 学习 ， 不断 地 进步 ，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>书籍</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "      <td>作者 真有 英国人 严谨 的 风格 ， 提出 观点 、 进行 论述 论证 ， 尽管 本人 对...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书籍</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "      <td>作者 长篇大论 借用 详细 报告 数据处理 工作 和 计算结果 支持 其新 观点 。 为什么...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>书籍</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "      <td>作者 在 战 几时 之前 用 了 ＂ 拥抱 ＂ 令人 叫绝 ． 日本 如果 没有 战败 ， ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书籍</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "      <td>作者 在 少年 时即 喜 阅读 ， 能 看出 他 精读 了 无数 经典 ， 因而 他 有 一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62769</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "      <td>我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...</td>\n",
       "      <td>我们 去 盐城 的 时候 那里 的 最低气温 只有 4 度 ， 晚上 冷得 要死 ， 居然 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62770</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9997</td>\n",
       "      <td>0</td>\n",
       "      <td>房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...</td>\n",
       "      <td>房间 很小 ， 整体 设施 老化 ， 和 四星 的 差距 很大 。 毛巾 太 破旧 了 。 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62771</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9998</td>\n",
       "      <td>0</td>\n",
       "      <td>我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！</td>\n",
       "      <td>我 感觉 不行 。 。 。 性价比 很差 。 不 知道 是 银川 都 这样 还是 怎么 的 ！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62772</th>\n",
       "      <td>酒店</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...</td>\n",
       "      <td>房间 时间 长 ， 进去 有点 异味 ！ 服务员 是不是 不够 用 啊 ！ 我 在 一楼 找...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62773</th>\n",
       "      <td>酒店</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...</td>\n",
       "      <td>老人 小孩 一 大家族 聚会 ， 选在 吴宫 泛太平洋 ， 以为 新加坡 品牌 一定 很 不...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62774 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat  Category_Index  label  \\\n",
       "0      书籍               1      1   \n",
       "1      书籍               2      1   \n",
       "2      书籍               3      1   \n",
       "3      书籍               4      1   \n",
       "4      书籍               5      1   \n",
       "...    ..             ...    ...   \n",
       "62769  酒店            9996      0   \n",
       "62770  酒店            9997      0   \n",
       "62771  酒店            9998      0   \n",
       "62772  酒店            9999      0   \n",
       "62773  酒店           10000      0   \n",
       "\n",
       "                                                  review  \\\n",
       "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...   \n",
       "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...   \n",
       "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...   \n",
       "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...   \n",
       "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...   \n",
       "...                                                  ...   \n",
       "62769  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...   \n",
       "62770  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...   \n",
       "62771                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！   \n",
       "62772  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...   \n",
       "62773  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...   \n",
       "\n",
       "                                                    分詞描述  \n",
       "0      ﻿ 做 父母 一定 要 有 刘墉 这样 的 心态 ， 不断 地 学习 ， 不断 地 进步 ，...  \n",
       "1      作者 真有 英国人 严谨 的 风格 ， 提出 观点 、 进行 论述 论证 ， 尽管 本人 对...  \n",
       "2      作者 长篇大论 借用 详细 报告 数据处理 工作 和 计算结果 支持 其新 观点 。 为什么...  \n",
       "3      作者 在 战 几时 之前 用 了 ＂ 拥抱 ＂ 令人 叫绝 ． 日本 如果 没有 战败 ， ...  \n",
       "4      作者 在 少年 时即 喜 阅读 ， 能 看出 他 精读 了 无数 经典 ， 因而 他 有 一...  \n",
       "...                                                  ...  \n",
       "62769  我们 去 盐城 的 时候 那里 的 最低气温 只有 4 度 ， 晚上 冷得 要死 ， 居然 ...  \n",
       "62770  房间 很小 ， 整体 设施 老化 ， 和 四星 的 差距 很大 。 毛巾 太 破旧 了 。 ...  \n",
       "62771    我 感觉 不行 。 。 。 性价比 很差 。 不 知道 是 银川 都 这样 还是 怎么 的 ！  \n",
       "62772  房间 时间 长 ， 进去 有点 异味 ！ 服务员 是不是 不够 用 啊 ！ 我 在 一楼 找...  \n",
       "62773  老人 小孩 一 大家族 聚会 ， 选在 吴宫 泛太平洋 ， 以为 新加坡 品牌 一定 很 不...  \n",
       "\n",
       "[62774 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分詞函數\n",
    "def segment_text(text):\n",
    "    # 檢查是否是字串，如果不是，則返回一個空字串\n",
    "    if isinstance(text, str):\n",
    "        return \" \".join(jieba.cut(text))\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# 對文字描述進行分詞\n",
    "data['分詞描述'] = data['review'].apply(segment_text)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f615cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 48437)\t1\n",
      "  (0, 50210)\t1\n",
      "  (0, 5951)\t1\n",
      "  (0, 14774)\t1\n",
      "  (0, 33575)\t1\n",
      "  (0, 26891)\t1\n",
      "  (0, 4061)\t1\n",
      "  (0, 55496)\t1\n",
      "  (0, 38364)\t1\n",
      "  (0, 50264)\t1\n"
     ]
    }
   ],
   "source": [
    "# 劃分數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['分詞描述'], data['cat'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 特徵提取 - 使用詞袋模型\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_vectorized[0])  # (i,j) f. -> 第i筆資料出現第j個詞的頻率次數f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d12ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率：0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.93      0.93      0.93       759\n",
      "          平板       0.77      0.79      0.78      1998\n",
      "          手机       0.95      0.73      0.83       482\n",
      "          水果       0.89      0.88      0.88      1936\n",
      "         洗发水       0.80      0.85      0.82      2008\n",
      "         热水器       1.00      0.05      0.10       117\n",
      "          蒙牛       0.99      0.92      0.96       409\n",
      "          衣服       0.86      0.88      0.87      1999\n",
      "         计算机       0.93      0.87      0.90       813\n",
      "          酒店       0.95      0.99      0.97      2034\n",
      "\n",
      "    accuracy                           0.87     12555\n",
      "   macro avg       0.91      0.79      0.80     12555\n",
      "weighted avg       0.87      0.87      0.87     12555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 訓練貝氏分類器\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# 預測並評估模型\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"準確率：{accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceaafa4",
   "metadata": {},
   "source": [
    "# Practice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37858ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率：0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.92      0.92      0.92       759\n",
      "          平板       0.76      0.70      0.73      1998\n",
      "          手机       0.78      0.77      0.78       482\n",
      "          水果       0.90      0.87      0.88      1936\n",
      "         洗发水       0.78      0.85      0.81      2008\n",
      "         热水器       0.93      0.35      0.51       117\n",
      "          蒙牛       0.94      0.99      0.97       409\n",
      "          衣服       0.84      0.88      0.86      1999\n",
      "         计算机       0.81      0.84      0.82       813\n",
      "          酒店       0.97      0.96      0.97      2034\n",
      "\n",
      "    accuracy                           0.85     12555\n",
      "   macro avg       0.86      0.81      0.82     12555\n",
      "weighted avg       0.85      0.85      0.85     12555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 讀取CSV文件\n",
    "data = pd.read_csv('simplified_dataset/simplified_raw_data.csv')  # 替換成你的CSV文件路徑\n",
    "\n",
    "# 將每個字都當作特徵，不進行分詞\n",
    "data['字符描述'] = data['review'].apply(lambda text: \" \".join(list(str(text))) if isinstance(text, str) else \"\")\n",
    "#print(data)\n",
    "\n",
    "# 劃分數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['字符描述'], data['cat'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 特徵提取 - 使用詞袋模型 (字符级别)\n",
    "vectorizer = CountVectorizer(analyzer='char')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# 訓練貝氏分類器\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# 預測並評估模型\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"準確率：{accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf16ff",
   "metadata": {},
   "source": [
    "# 單詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef5c3592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MultinomialNB, Feature Extraction: Character Level\n",
      "Accuracy: 0.85\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.92      0.92      0.92       759\n",
      "          平板       0.76      0.70      0.73      1998\n",
      "          手机       0.78      0.77      0.78       482\n",
      "          水果       0.90      0.87      0.88      1936\n",
      "         洗发水       0.78      0.85      0.81      2008\n",
      "         热水器       0.93      0.35      0.51       117\n",
      "          蒙牛       0.94      0.99      0.97       409\n",
      "          衣服       0.84      0.88      0.86      1999\n",
      "         计算机       0.81      0.84      0.82       813\n",
      "          酒店       0.97      0.96      0.97      2034\n",
      "\n",
      "    accuracy                           0.85     12555\n",
      "   macro avg       0.86      0.81      0.82     12555\n",
      "weighted avg       0.85      0.85      0.85     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 699   26    9    2   12    0    2    1    6    2]\n",
      " [  15 1400   50   53  231    0    7  155   78    9]\n",
      " [   6   63  371    5    2    0    0    8   23    4]\n",
      " [  13   52    3 1685  109    1    4   53   11    5]\n",
      " [   8  121    5   67 1698    2    7   70   18   12]\n",
      " [   0   13    0   12   20   41    1   19    8    3]\n",
      " [   2    0    0    0    0    0  406    0    0    1]\n",
      " [   8   88    3   41   90    0    4 1751    4   10]\n",
      " [   5   74   28    5   12    0    0    3  679    7]\n",
      " [   7   15    4    7    7    0    1   19   12 1962]]\n",
      "\n",
      "Classifier: DecisionTree, Feature Extraction: Character Level\n",
      "Accuracy: 0.79\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.85      0.82      0.83       759\n",
      "          平板       0.66      0.65      0.65      1998\n",
      "          手机       0.65      0.61      0.63       482\n",
      "          水果       0.84      0.85      0.85      1936\n",
      "         洗发水       0.73      0.74      0.73      2008\n",
      "         热水器       0.44      0.38      0.40       117\n",
      "          蒙牛       0.99      0.99      0.99       409\n",
      "          衣服       0.80      0.84      0.82      1999\n",
      "         计算机       0.73      0.73      0.73       813\n",
      "          酒店       0.94      0.92      0.93      2034\n",
      "\n",
      "    accuracy                           0.79     12555\n",
      "   macro avg       0.76      0.75      0.76     12555\n",
      "weighted avg       0.79      0.79      0.79     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 623   25   12   19   30    6    0   16   17   11]\n",
      " [  28 1290   77   77  225   16    0  135  106   44]\n",
      " [  11   96  292    8   10    4    0   18   36    7]\n",
      " [  21   81    1 1648  105    4    1   59    6   10]\n",
      " [  20  208   10  107 1482   10    0  126   24   21]\n",
      " [   2   29    5    4   20   44    0    5    4    4]\n",
      " [   0    0    0    2    0    0  406    0    0    1]\n",
      " [   5  101   10   54  108   10    0 1679    7   25]\n",
      " [  13   97   36   13   42    2    0   14  590    6]\n",
      " [  14   36    6   19   19    5    3   42   17 1873]]\n",
      "\n",
      "Classifier: RandomForest, Feature Extraction: Character Level\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.98      0.89      0.93       759\n",
      "          平板       0.71      0.80      0.75      1998\n",
      "          手机       0.97      0.59      0.74       482\n",
      "          水果       0.91      0.88      0.89      1936\n",
      "         洗发水       0.77      0.85      0.81      2008\n",
      "         热水器       0.97      0.29      0.45       117\n",
      "          蒙牛       0.99      1.00      0.99       409\n",
      "          衣服       0.86      0.90      0.88      1999\n",
      "         计算机       0.91      0.74      0.82       813\n",
      "          酒店       0.97      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.86     12555\n",
      "   macro avg       0.90      0.79      0.82     12555\n",
      "weighted avg       0.87      0.86      0.86     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 679   21    1   11   21    0    0   13    4    9]\n",
      " [   4 1593    3   39  210    1    1  112   23   12]\n",
      " [   0  138  285    7    5    0    0   16   28    3]\n",
      " [   2   52    0 1703  129    0    0   45    1    4]\n",
      " [   1  143    1   64 1716    0    2   71    1    9]\n",
      " [   2   40    0    0   24   34    0   11    1    5]\n",
      " [   0    0    0    0    0    0  409    0    0    0]\n",
      " [   3   81    0   31   72    0    1 1801    0   10]\n",
      " [   3  135    3   18   32    0    1   13  602    6]\n",
      " [   2   26    0    6   15    0    1   18    1 1965]]\n",
      "\n",
      "Classifier: SVM, Feature Extraction: Character Level\n",
      "Accuracy: 0.70\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.93      0.61      0.73       759\n",
      "          平板       0.54      0.57      0.56      1998\n",
      "          手机       0.88      0.27      0.41       482\n",
      "          水果       0.86      0.75      0.80      1936\n",
      "         洗发水       0.64      0.72      0.68      2008\n",
      "         热水器       0.00      0.00      0.00       117\n",
      "          蒙牛       0.99      0.42      0.59       409\n",
      "          衣服       0.55      0.88      0.68      1999\n",
      "         计算机       0.71      0.66      0.68       813\n",
      "          酒店       0.96      0.80      0.87      2034\n",
      "\n",
      "    accuracy                           0.70     12555\n",
      "   macro avg       0.71      0.57      0.60     12555\n",
      "weighted avg       0.73      0.70      0.69     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 460   93    0   21   80    0    0   41   42   22]\n",
      " [   2 1146    5   48  253    0    0  499   36    9]\n",
      " [   4  158  128    5    7    0    0   76   91   13]\n",
      " [   7  106    0 1453  207    0    0  150    8    5]\n",
      " [   6  210    1   44 1448    0    0  283   10    6]\n",
      " [   1   24    0    4   36    0    0   47    2    3]\n",
      " [   5   53    0   19   26    0  172  115   17    2]\n",
      " [   1   75    0   37  121    0    1 1753    8    3]\n",
      " [   6  159   11   28   64    0    0    5  534    6]\n",
      " [   2  107    1   29   32    0    0  225    4 1634]]\n",
      "\n",
      "Classifier: MLP, Feature Extraction: Character Level\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.95      0.92      0.93       759\n",
      "          平板       0.78      0.79      0.79      1998\n",
      "          手机       0.85      0.81      0.83       482\n",
      "          水果       0.89      0.89      0.89      1936\n",
      "         洗发水       0.81      0.81      0.81      2008\n",
      "         热水器       0.65      0.62      0.63       117\n",
      "          蒙牛       0.99      0.97      0.98       409\n",
      "          衣服       0.87      0.88      0.88      1999\n",
      "         计算机       0.87      0.87      0.87       813\n",
      "          酒店       0.96      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.87     12555\n",
      "   macro avg       0.86      0.85      0.86     12555\n",
      "weighted avg       0.87      0.87      0.87     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 696   13    8    5   11    1    1    6    7   11]\n",
      " [   8 1580   21   50  169   11    0   95   48   16]\n",
      " [   3   46  391    3    5    2    0    6   23    3]\n",
      " [   5   57    2 1726   83    1    0   46    8    8]\n",
      " [   5  157    3  102 1628   10    2   79   10   12]\n",
      " [   0   27    1    2    8   72    0    4    1    2]\n",
      " [   2    1    0    5    2    0  397    1    0    1]\n",
      " [   1   83    8   28   80   11    1 1768    5   14]\n",
      " [   6   49   21    5   13    2    0    3  709    5]\n",
      " [   5   11    6   11    8    1    0   16    5 1971]]\n",
      "\n",
      "RESULTS\n",
      "Classifier: MultinomialNB, Feature Extraction: TfidfVectorizer,: 0.85\n",
      "Classifier: DecisionTree, Feature Extraction: TfidfVectorizer,: 0.79\n",
      "Classifier: RandomForest, Feature Extraction: TfidfVectorizer,: 0.86\n",
      "Classifier: SVM, Feature Extraction: TfidfVectorizer,: 0.70\n",
      "Classifier: MLP, Feature Extraction: TfidfVectorizer,: 0.87\n",
      "\n",
      "Classification Finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# 讀取CSV文件\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "# 初始化不同的分類器\n",
    "def initialize_classifiers():\n",
    "    classifiers = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(),\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"MLP\": MLPClassifier()\n",
    "    }\n",
    "    return classifiers\n",
    "\n",
    "# 訓練、評估\n",
    "def train_and_evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)  #計算混淆矩陣\n",
    "    return {'accuracy': accuracy, 'classification_report': classification_rep, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'simplified_dataset/simplified_raw_data.csv'\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # 將NaN值替換為空字串\n",
    "    data['review'] = data['review'].fillna('')\n",
    "    \n",
    "    X = data['review']\n",
    "    y = data['cat']\n",
    "    \n",
    "    classifiers = initialize_classifiers()\n",
    "    \n",
    "    results_dict = {}  #用於儲存结果\n",
    "    \n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction: Character Level\")\n",
    "        \n",
    "        \n",
    "        # 將每個字都當作特徵，不進行分詞\n",
    "        data['字符描述'] = data['review'].apply(lambda text: \" \".join(list(str(text))) if isinstance(text, str) else \"\")\n",
    "        #print(data)\n",
    "\n",
    "        # 劃分數據集為訓練集和測試集\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data['字符描述'], data['cat'], test_size=0.2, random_state=42)\n",
    "\n",
    "        # 特徵提取 - 使用詞袋模型 (字符级别)\n",
    "        vectorizer = CountVectorizer(analyzer='char')\n",
    "        X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "        X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "        \n",
    "        results = train_and_evaluate_classifier(classifier, X_train_vectorized, X_test_vectorized, y_train, y_test)\n",
    "        # 儲存结果到字典\n",
    "        results_dict[(clf_name, method_name)] = results\n",
    "\n",
    "        print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "        print(f\"Classification Report:\\n{results['classification_report']}\\n\")\n",
    "        print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\\n\")\n",
    "        \n",
    "    \n",
    "    # 統整結果\n",
    "    print(\"RESULTS\")\n",
    "    for(clf_name, method_name), results in results_dict.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction: {method_name},: {results['accuracy']:.2f}\")\n",
    "\n",
    "        \n",
    "    print(\"\\nClassification Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54e342",
   "metadata": {},
   "source": [
    "# 斷詞及TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b9acc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MultinomialNB, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.85\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.91      0.92      0.92       759\n",
      "          平板       0.76      0.70      0.73      1998\n",
      "          手机       0.80      0.77      0.78       482\n",
      "          水果       0.90      0.87      0.88      1936\n",
      "         洗发水       0.78      0.85      0.81      2008\n",
      "         热水器       0.89      0.36      0.51       117\n",
      "          蒙牛       0.94      0.99      0.97       409\n",
      "          衣服       0.84      0.88      0.86      1999\n",
      "         计算机       0.82      0.84      0.83       813\n",
      "          酒店       0.97      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.85     12555\n",
      "   macro avg       0.86      0.81      0.83     12555\n",
      "weighted avg       0.85      0.85      0.85     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 699   26    9    2   11    0    2    1    6    3]\n",
      " [  15 1394   48   53  240    0    7  154   79    8]\n",
      " [   6   64  373    5    2    0    0    8   20    4]\n",
      " [  14   52    4 1683  111    2    3   52   10    5]\n",
      " [  10  120    6   68 1697    2    7   69   16   13]\n",
      " [   0   14    0   11   20   42    1   18    8    3]\n",
      " [   2    0    0    0    0    0  406    0    0    1]\n",
      " [   8   86    4   37   90    0    5 1754    4   11]\n",
      " [   4   74   22    6   12    0    0    3  685    7]\n",
      " [   7   15    3    6    6    1    1   20   12 1963]]\n",
      "\n",
      "Classifier: MultinomialNB, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.98      0.05      0.10       759\n",
      "          平板       0.46      0.39      0.42      1998\n",
      "          手机       1.00      0.03      0.06       482\n",
      "          水果       0.29      0.77      0.42      1936\n",
      "         洗发水       0.59      0.47      0.52      2008\n",
      "         热水器       0.00      0.00      0.00       117\n",
      "          蒙牛       1.00      0.19      0.32       409\n",
      "          衣服       0.58      0.61      0.60      1999\n",
      "         计算机       0.92      0.12      0.21       813\n",
      "          酒店       0.74      0.64      0.68      2034\n",
      "\n",
      "    accuracy                           0.47     12555\n",
      "   macro avg       0.66      0.33      0.33     12555\n",
      "weighted avg       0.61      0.47      0.45     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  40   59    0  419   40    0    0   66    0  135]\n",
      " [   0  778    0  671  241    0    0  254    2   52]\n",
      " [   0  110   14  210   17    0    0   65    4   62]\n",
      " [   0  127    0 1500  149    0    0  121    0   39]\n",
      " [   0  203    0  638  940    0    0  188    1   38]\n",
      " [   0   23    0   39   26    0    0   25    0    4]\n",
      " [   1   18    0  254    8    0   79   24    0   25]\n",
      " [   0  115    0  519  116    0    0 1220    0   29]\n",
      " [   0  163    0  365   38    0    0   73   94   80]\n",
      " [   0   88    0  559   31    0    0   63    1 1292]]\n",
      "\n",
      "Classifier: DecisionTree, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.84      0.79      0.82       759\n",
      "          平板       0.64      0.66      0.65      1998\n",
      "          手机       0.61      0.58      0.59       482\n",
      "          水果       0.82      0.84      0.83      1936\n",
      "         洗发水       0.73      0.71      0.72      2008\n",
      "         热水器       0.36      0.37      0.36       117\n",
      "          蒙牛       1.00      0.99      0.99       409\n",
      "          衣服       0.80      0.83      0.82      1999\n",
      "         计算机       0.70      0.66      0.68       813\n",
      "          酒店       0.94      0.92      0.93      2034\n",
      "\n",
      "    accuracy                           0.78     12555\n",
      "   macro avg       0.74      0.74      0.74     12555\n",
      "weighted avg       0.78      0.78      0.78     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 603   31   11   18   27    1    0   28   20   20]\n",
      " [  22 1326   91   87  212   20    0  122   96   22]\n",
      " [  11  111  280    4   11    2    0   17   40    6]\n",
      " [  10   88    5 1618  112   10    0   71   11   11]\n",
      " [  23  207    7  139 1434   24    0  112   34   28]\n",
      " [   1   30    6    6   16   43    0    6    7    2]\n",
      " [   0    0    0    2    0    0  406    0    0    1]\n",
      " [  18  119    8   51  102    7    0 1662   10   22]\n",
      " [  14  122   47   29   29    5    0   16  539   12]\n",
      " [  18   33    6   15   24    7    2   32   16 1881]]\n",
      "\n",
      "Classifier: DecisionTree, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.39\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.54      0.15      0.23       759\n",
      "          平板       0.21      0.71      0.32      1998\n",
      "          手机       0.46      0.19      0.27       482\n",
      "          水果       0.62      0.37      0.46      1936\n",
      "         洗发水       0.50      0.28      0.36      2008\n",
      "         热水器       0.16      0.14      0.15       117\n",
      "          蒙牛       0.82      0.33      0.47       409\n",
      "          衣服       0.58      0.43      0.49      1999\n",
      "         计算机       0.61      0.20      0.30       813\n",
      "          酒店       0.81      0.40      0.54      2034\n",
      "\n",
      "    accuracy                           0.39     12555\n",
      "   macro avg       0.53      0.32      0.36     12555\n",
      "weighted avg       0.55      0.39      0.41     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 111  492   11   36   19    0    8   30   17   35]\n",
      " [  13 1415   33   93  176   23    2  185   24   34]\n",
      " [   7  301   90   13   10    0    1   22   17   21]\n",
      " [  10  917    4  711  132   10    3  125    3   21]\n",
      " [  11 1094    2  112  572   21    4  159    9   24]\n",
      " [   0   71    2    5   12   16    0    9    0    2]\n",
      " [   3  242    2    9    6    0  133    6    0    8]\n",
      " [   6  839    7   90  143   22    4  854    6   28]\n",
      " [  10  501   29   29   32    2    0   25  165   20]\n",
      " [  33  974   14   54   38    4    7   62   29  819]]\n",
      "\n",
      "Classifier: RandomForest, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.98      0.88      0.93       759\n",
      "          平板       0.71      0.82      0.76      1998\n",
      "          手机       0.96      0.63      0.76       482\n",
      "          水果       0.91      0.88      0.89      1936\n",
      "         洗发水       0.78      0.85      0.81      2008\n",
      "         热水器       0.92      0.28      0.43       117\n",
      "          蒙牛       0.99      1.00      0.99       409\n",
      "          衣服       0.86      0.90      0.88      1999\n",
      "         计算机       0.94      0.74      0.83       813\n",
      "          酒店       0.98      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.86     12555\n",
      "   macro avg       0.90      0.79      0.82     12555\n",
      "weighted avg       0.87      0.86      0.86     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 669   27    0   10   27    0    0   14    4    8]\n",
      " [   3 1631    8   35  192    1    0  106   12   10]\n",
      " [   1  130  302    5    4    0    0   15   23    2]\n",
      " [   3   68    1 1696  114    1    1   49    0    3]\n",
      " [   1  152    0   63 1705    1    2   75    1    8]\n",
      " [   0   42    0    2   27   33    0   11    0    2]\n",
      " [   0    0    0    0    0    0  409    0    0    0]\n",
      " [   2   95    0   29   67    0    1 1793    0   12]\n",
      " [   5  140    3   15   27    0    0   15  603    5]\n",
      " [   1   19    1   13   17    0    1   17    0 1965]]\n",
      "\n",
      "Classifier: RandomForest, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.66      0.16      0.26       759\n",
      "          平板       0.22      0.72      0.34      1998\n",
      "          手机       0.54      0.18      0.27       482\n",
      "          水果       0.68      0.39      0.50      1936\n",
      "         洗发水       0.54      0.36      0.44      2008\n",
      "         热水器       0.15      0.13      0.14       117\n",
      "          蒙牛       0.84      0.34      0.49       409\n",
      "          衣服       0.61      0.48      0.54      1999\n",
      "         计算机       0.69      0.22      0.33       813\n",
      "          酒店       0.85      0.45      0.59      2034\n",
      "\n",
      "    accuracy                           0.43     12555\n",
      "   macro avg       0.58      0.34      0.39     12555\n",
      "weighted avg       0.59      0.43      0.45     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 121  473    8   31   35    0    5   39   16   31]\n",
      " [   9 1445   20   75  197   21    3  177   22   29]\n",
      " [   7  287   88   14   22    2    0   22   18   22]\n",
      " [   5  868    1  761  140   15    5  116    4   21]\n",
      " [   8  958    4   99  731   22    5  165    2   14]\n",
      " [   1   72    2    2   14   15    0    9    0    2]\n",
      " [   2  240    1    6    6    0  141    6    0    7]\n",
      " [   6  797    7   55  121   17    3  964    3   26]\n",
      " [   9  496   26   26   35    3    1   27  175   15]\n",
      " [  15  895    7   56   49    7    4   66   15  920]]\n",
      "\n",
      "Classifier: SVM, Feature Extraction: CountVectorizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.96      0.88      0.92       759\n",
      "          平板       0.71      0.82      0.76      1998\n",
      "          手机       0.94      0.65      0.77       482\n",
      "          水果       0.94      0.85      0.89      1936\n",
      "         洗发水       0.79      0.83      0.81      2008\n",
      "         热水器       0.97      0.32      0.48       117\n",
      "          蒙牛       1.00      0.99      0.99       409\n",
      "          衣服       0.85      0.90      0.87      1999\n",
      "         计算机       0.92      0.83      0.87       813\n",
      "          酒店       0.92      0.95      0.94      2034\n",
      "\n",
      "    accuracy                           0.86     12555\n",
      "   macro avg       0.90      0.80      0.83     12555\n",
      "weighted avg       0.87      0.86      0.86     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 668   25    0    1   14    0    0   14    4   33]\n",
      " [   4 1629    7   24  165    0    1  119   28   21]\n",
      " [   4   97  313    3    2    0    0   13   13   37]\n",
      " [   2   82    0 1636  139    0    0   56    2   19]\n",
      " [   7  185    1   35 1675    0    0   80    5   20]\n",
      " [   0   41    0    1   22   37    0   10    2    4]\n",
      " [   0    1    0    1    0    0  405    0    0    2]\n",
      " [   2   95    1   17   64    0    1 1808    2    9]\n",
      " [   6   80   10    5   19    0    0    7  674   12]\n",
      " [   6   44    1    9    9    1    0   32    3 1929]]\n",
      "\n",
      "Classifier: SVM, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.76      0.11      0.19       759\n",
      "          平板       0.26      0.69      0.38      1998\n",
      "          手机       0.80      0.09      0.16       482\n",
      "          水果       0.69      0.50      0.58      1936\n",
      "         洗发水       0.60      0.44      0.51      2008\n",
      "         热水器       1.00      0.07      0.13       117\n",
      "          蒙牛       0.96      0.28      0.43       409\n",
      "          衣服       0.70      0.53      0.60      1999\n",
      "         计算机       0.66      0.20      0.31       813\n",
      "          酒店       0.56      0.63      0.60      2034\n",
      "\n",
      "    accuracy                           0.48     12555\n",
      "   macro avg       0.70      0.35      0.39     12555\n",
      "weighted avg       0.61      0.48      0.48     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  83  382    1   24   25    0    1   21    9  213]\n",
      " [   3 1384    4   93  217    0    0  160   20  117]\n",
      " [   3  246   43    6   10    0    0   15   18  141]\n",
      " [   2  643    0  974  141    0    1   81    4   90]\n",
      " [   1  778    0  149  883    0    2  114    6   75]\n",
      " [   0   60    1    4   21    8    0   11    0   12]\n",
      " [   6  206    1    7    6    0  114    2    2   65]\n",
      " [   1  626    0   86  109    0    0 1069   11   97]\n",
      " [   5  386    3   16   36    0    0   23  162  182]\n",
      " [   5  617    1   44   27    0    1   42   14 1283]]\n",
      "\n",
      "Classifier: MLP, Feature Extraction: CountVectorizer\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.94      0.93      0.93       759\n",
      "          平板       0.77      0.79      0.78      1998\n",
      "          手机       0.82      0.81      0.82       482\n",
      "          水果       0.89      0.88      0.88      1936\n",
      "         洗发水       0.82      0.82      0.82      2008\n",
      "         热水器       0.65      0.56      0.61       117\n",
      "          蒙牛       0.99      0.97      0.98       409\n",
      "          衣服       0.87      0.90      0.88      1999\n",
      "         计算机       0.88      0.85      0.87       813\n",
      "          酒店       0.97      0.97      0.97      2034\n",
      "\n",
      "    accuracy                           0.87     12555\n",
      "   macro avg       0.86      0.85      0.85     12555\n",
      "weighted avg       0.87      0.87      0.87     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 703   12    8   10    7    0    1    8    4    6]\n",
      " [   9 1587   25   49  152   16    2  104   41   13]\n",
      " [   3   51  389    1    3    2    0    5   23    5]\n",
      " [   6   64    2 1700   95    1    0   58    4    6]\n",
      " [  10  160    4   96 1637    5    0   74   10   12]\n",
      " [   0   28    2    1   10   66    0    5    3    2]\n",
      " [   2    0    0    4    2    0  398    2    0    1]\n",
      " [   1   79    9   34   64    7    0 1797    2    6]\n",
      " [   9   53   27    2   12    3    0    7  693    7]\n",
      " [   8   14    6    9    9    1    0   16    5 1966]]\n",
      "\n",
      "Classifier: MLP, Feature Extraction: TfidfVectorizer\n",
      "Accuracy: 0.51\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          书籍       0.64      0.33      0.44       759\n",
      "          平板       0.26      0.67      0.38      1998\n",
      "          手机       0.61      0.34      0.44       482\n",
      "          水果       0.70      0.52      0.60      1936\n",
      "         洗发水       0.61      0.41      0.49      2008\n",
      "         热水器       0.21      0.19      0.20       117\n",
      "          蒙牛       0.88      0.39      0.54       409\n",
      "          衣服       0.66      0.55      0.60      1999\n",
      "         计算机       0.63      0.43      0.51       813\n",
      "          酒店       0.82      0.61      0.70      2034\n",
      "\n",
      "    accuracy                           0.51     12555\n",
      "   macro avg       0.60      0.44      0.49     12555\n",
      "weighted avg       0.62      0.51      0.53     12555\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 250  375   12   17   24    1    6   19   22   33]\n",
      " [  19 1337   26  112  198   23    0  169   61   53]\n",
      " [  16  206  166    5    7    0    0   18   37   27]\n",
      " [  15  619    5 1012  118    8    2  109   13   35]\n",
      " [  15  770    5  152  815   23    4  166   20   38]\n",
      " [   0   51    1    6   16   22    0   15    0    6]\n",
      " [  15  203    4    6    5    0  161    3    4    8]\n",
      " [  13  614    7   74  111   23    2 1099   21   35]\n",
      " [  12  332   33   12   16    3    6   22  346   31]\n",
      " [  35  597   13   40   31    4    3   50   26 1235]]\n",
      "\n",
      "RESULTS\n",
      "Classifier: MultinomialNB, Feature Extraction: CountVectorizer,: 0.85\n",
      "Classifier: MultinomialNB, Feature Extraction: TfidfVectorizer,: 0.47\n",
      "Classifier: DecisionTree, Feature Extraction: CountVectorizer,: 0.78\n",
      "Classifier: DecisionTree, Feature Extraction: TfidfVectorizer,: 0.39\n",
      "Classifier: RandomForest, Feature Extraction: CountVectorizer,: 0.86\n",
      "Classifier: RandomForest, Feature Extraction: TfidfVectorizer,: 0.43\n",
      "Classifier: SVM, Feature Extraction: CountVectorizer,: 0.86\n",
      "Classifier: SVM, Feature Extraction: TfidfVectorizer,: 0.48\n",
      "Classifier: MLP, Feature Extraction: CountVectorizer,: 0.87\n",
      "Classifier: MLP, Feature Extraction: TfidfVectorizer,: 0.51\n",
      "\n",
      "Classification Finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 讀取CSV文件\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# 特徵提取 - 使用CountVectorizer模型 \n",
    "def count_vectorizer(X_train, X_test):\n",
    "    vectorizer = CountVectorizer(analyzer='char')\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    return X_train_vectorized, X_test_vectorized\n",
    "\n",
    "# 特徵提取 - TF-IDF模型\n",
    "def tfidf_vectorizer(X_train, X_test):\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word')\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "# 初始化不同的分類器\n",
    "def initialize_classifiers():\n",
    "    classifiers = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(),\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"MLP\": MLPClassifier()\n",
    "    }\n",
    "    return classifiers\n",
    "\n",
    "# 訓練、評估\n",
    "def train_and_evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)  #計算混淆矩陣\n",
    "    return {'accuracy': accuracy, 'classification_report': classification_rep, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'simplified_dataset/simplified_raw_data.csv'\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # 將NaN值替換為空字串\n",
    "    data['review'] = data['review'].fillna('')\n",
    "    \n",
    "    X = data['review']\n",
    "    y = data['cat']\n",
    "    \n",
    "    classifiers = initialize_classifiers()\n",
    "    feature_extraction_methods = {\n",
    "        \"CountVectorizer\": count_vectorizer,\n",
    "        \"TfidfVectorizer\": tfidf_vectorizer,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # 初始化结果字典\n",
    "    results_dict = {}\n",
    "\n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        for method_name, feature_extractor in feature_extraction_methods.items():\n",
    "            print(f\"Classifier: {clf_name}, Feature Extraction: {method_name}\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            X_train_vectorized, X_test_vectorized = feature_extractor(X_train, X_test)\n",
    "            results = train_and_evaluate_classifier(classifier, X_train_vectorized, X_test_vectorized, y_train, y_test)\n",
    "\n",
    "            # 儲存结果到字典\n",
    "            results_dict[(clf_name, method_name)] = results\n",
    "\n",
    "            print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "            print(f\"Classification Report:\\n{results['classification_report']}\\n\")\n",
    "            print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # 統整結果\n",
    "    print(\"RESULTS\")\n",
    "    for(clf_name, method_name), results in results_dict.items():\n",
    "        print(f\"Classifier: {clf_name}, Feature Extraction: {method_name},: {results['accuracy']:.2f}\")\n",
    "\n",
    "        \n",
    "    print(\"\\nClassification Finish\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d422a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
